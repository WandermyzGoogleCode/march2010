
%% bare_conf.tex
%% V1.3
%% 2007/01/11
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.7 or later) with an IEEE conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_jrnl_compsoc.tex
%%*************************************************************************

% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. IEEE's font choices can trigger bugs that do  ***
% *** not appear when using other class files.                            ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



% Note that the a4paper option is mainly intended so that authors in
% countries using A4 can easily print to A4 and see how their papers will
% look in print - the typesetting of the document will not typically be
% affected with changes in paper size (but the bottom and side margins will).
% Use the testflow package mentioned above to verify correct handling of
% both paper sizes by the user's LaTeX system.
%
% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
\documentclass[10pt, conference, compsocconf]{IEEEtran}
% Add the compsocconf option for Computer Society conferences.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 4.0 (2003-05-27) and later if using hyperref.sty. cite.sty does
% not currently provide for hyperlinked citations.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at: 
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found as epslatex.ps or
% epslatex.pdf at: http://www.ctan.org/tex-archive/info/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


%\usepackage{mdwmath}
%\usepackage{mdwtab}
% Also highly recommended is Mark Wooding's extremely powerful MDW tools,
% especially mdwmath.sty and mdwtab.sty which are used to format equations
% and tables, respectively. The MDWtools set is already installed on most
% LaTeX systems. The lastest version and documentation is available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/mdwtools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.


%\usepackage{eqparbox}
% Also of notable interest is Scott Pakin's eqparbox package for creating
% (automatically sized) equal width boxes - aka "natural width parboxes".
% Available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/eqparbox/





% *** SUBFIGURE PACKAGES ***
%\usepackage[tight,footnotesize]{subfigure}
% subfigure.sty was written by Steven Douglas Cochran. This package makes it
% easy to put subfigures in your figures. e.g., "Figure 1a and 1b". For IEEE
% work, it is a good idea to load it with the tight package option to reduce
% the amount of white space around the subfigures. subfigure.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at:
% http://www.ctan.org/tex-archive/obsolete/macros/latex/contrib/subfigure/
% subfigure.sty has been superceeded by subfig.sty.



%\usepackage[caption=false]{caption}
%\usepackage[font=footnotesize]{subfig}
% subfig.sty, also written by Steven Douglas Cochran, is the modern
% replacement for subfigure.sty. However, subfig.sty requires and
% automatically loads Axel Sommerfeldt's caption.sty which will override
% IEEEtran.cls handling of captions and this will result in nonIEEE style
% figure/table captions. To prevent this problem, be sure and preload
% caption.sty with its "caption=false" package option. This is will preserve
% IEEEtran.cls handing of captions. Version 1.3 (2005/06/28) and later 
% (recommended due to many improvements over 1.2) of subfig.sty supports
% the caption=false option directly:
%\usepackage[caption=false,font=footnotesize]{subfig}
%
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/
% The latest version and documentation of caption.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/caption/




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/



%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Documentation is contained in the stfloats.sty comments as well as in the
% presfull.pdf file. Do not use the stfloats baselinefloat ability as IEEE
% does not allow \baselineskip to stretch. Authors submitting work to the
% IEEE should note that IEEE rarely uses double column equations and
% that authors should try to avoid such use. Do not be tempted to use the
% cuted.sty or midfloat.sty packages (also by Sigitas Tolusis) as IEEE does
% not format its papers in such ways.





% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/misc/
% Read the url.sty source comments for usage information. Basically,
% \url{my_url_here}.





% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\usepackage{graphicx}
\newtheorem{mydef}{Definition}
\newtheorem{mylemma}{Lemma}
\newtheorem{mytheorem}{Theorem}
\newtheorem{mycor}{Corollary}

\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Anti Brute Force on Very Low Entropy Deterministic Encryption}


% author names and affiliations
% use a multiple column layout for up to two different
% affiliations

\author{\IEEEauthorblockN{Authors Name/s per 1st Affiliation (Author)}
\IEEEauthorblockA{line 1 (of Affiliation): dept. name of organization\\
line 2: name of organization, acronyms acceptable\\
line 3: City, Country\\
line 4: Email: name@xyz.com}
\and
\IEEEauthorblockN{Authors Name/s per 2nd Affiliation (Author)}
\IEEEauthorblockA{line 1 (of Affiliation): dept. name of organization\\
line 2: name of organization, acronyms acceptable\\
line 3: City, Country\\
line 4: Email: name@xyz.com}
}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle


\begin{abstract}
	Some information has a very small domain set. In that case, any
	deterministic encryption could only
	achieve a very low entropy bounded by the size of domain set.
	However, the deterministic encryption is required
	in situations such as hashing or generating an index or identity for a
	given information. 
	
	For such very low entropy encryption, the adversary does not need to
	attempt every possible key. Instead, a successful brute force attack
	to enumerate every possible
	plain text and check whether the cipher text is the same
	would be easy. A secured system
	is designed and implemented to defend that attack.
	That secured system is called defender system for the reason that it's based
	on a simple idea called defender model from us. 
	
	To ensure the security in a theoretical aspect
	for such cases, this paper uses conditional entropy instead of mere entropy.
	The conditional entropy measures the difficulty for an adversary to
	derive the information considering all related information 
	that adversary has already achieved. 
	In this system,
	a relatively high lower
	bound for conditional entropy can be guaranteed even with 
	a computationally-unbounded adversary who launches brute force attacks as above.
	In this paper, a very easy proof and some other approximation
	and experiment are given to show the lower bound.
	The practical meaning of conditional entropy's lower bound is also
	given from the aspect of min-entropy.
	
\end{abstract}

\begin{IEEEkeywords}
[TODO]component; formatting; style; styling;

\end{IEEEkeywords}


% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
% no \IEEEPARstart
	Deterministic encryption for an information from
	a very small domain set is important for some social
	network systems such as LiveS Cube. LiveS Cube\footnote{this is a system still 
	under developing} is a system to
	build a social network based on the address books in cellphones.
	In that social network, each node is indexed by a cipher text generated
	from the cellphone number
	of its user. Therefore, a huge network could be easily established
	using existing address books in numerous of cellphones without
	any additional effort of the users. However, cellphone numbers are
	one of the most important privacy[ref] so the security of preventing
	someone getting the corresponding cellphone number from its index 
	is the base of the system.
	
	But the security
	of such deterministic encryption is hard to be guaranteed, especially
	on a level that is not dependent on social network operators[ref].
	It's true that the encryption could use a very strong key
	so that it's almost impossible to enumerate the right key to convert cipher text
	to plain text. However, the function to get the corresponding
	cipher text from a given plain text must be permitted for all
	social network operators and normal users, otherwise the social network
	system could not operate.
	Therefore, brute force attack can enumerate all possible values from the
	small domain set and establish a table maps any cipher text
	to its plain text as long as the encryption
	does not change. In such case, the conditional entropy \cite{cond_entropy:1, cond_entropy:2} given that table
	is $0$ since there's no uncertainty for the adversary to get the plain text.
	Even for a large domain set which has a quite high entropy, a
	computationally-unbounded adversary could establish that table
	and the conditional entropy drops to $0$ again. 
	So it's not the mere entropy \cite{entropy} that
	determines the security, but the conditional entropy considering
	all the information that adversary could gain during attacks.
	The related entropic security analysis will be reviewed
	in section \ref{sec_rw}.
	
	Therefore, even for the very low entropy information, 
	there is still possibility to ensure the
	theoretical security by giving a lower bound for conditional entropy
	considering all information gained by possible brute force attacks from adversary.
	The defender model is an easy model based on a simple idea to achieve that goal.
	This model is used in LiveS Cube system so a defender system is made.
	The analysis in the following sections is mainly based on that system.
	The result shows that the system could ensure a relatively high lower bound
	of conditional entropy in a very efficient way: suppose that the original entropy
	is $D$, a lower bound of $c_1 D = \Omega(D)$ can be guaranteed
	by performing one defend operation after $2^{c_2 D} = 2^{\Omega(D)}$ 
	brute force attacks. Since the analysis is quite simple, the
	bound estimated is believed not to be so tight. 
	Considering the result derived by some other
	more complex, however not accurate, only approximate ways, it is believed
	that the tight lower bound for this system is much higher than what we proved.
	Experiments are also conducted to evaluate the lower bound. They confirm that
	our lower bound is valid but far from tight in some cases. At last, a practical
	meaning of our conditional entropy's lower bound is given from the aspect
	of min-entropy: the adversary is expected to compromise the security in a
	chance of only $2^{-\Omega(D)}$.
	
	In sum, our contribution is threefold. Firstly, to solve the security problem
	of low entropy information's deterministic encryption, defender model and system
	are proposed. Secondly, conditional entropy is introduced to analysis
	the theoretical security of system under computationally-unbounded brute force
	attacks and a simple lower bound of conditional entropy is proved in defender system. 
	Thirdly, approximation and experiments
	are conducted to further check and evaluate our analysis and a practical meaning
	of our conditional entropy based proof is derived from the experiment 
	in the aspect of min-entropy.
	
	In the following sections, firstly some related works
	about privacy problems in social network systems and
	entropic security are reviewed. The defender model and system will be
	introduced after that. Then a simple proof for the lower bound of conditional entropy
	is given. Finally some other approximate and experimental ways to estimate the conditional
	entropy are discussed.
	
% You must have at least 2 lines in the paragraph with the drop letter
% (should never be an issue)

\section{Related Work}	\label{sec_rw}
	\subsection{Entropy and Entropic Security}
	Entropy\cite{entropy} measures the uncertainty of an information. Intuitively, it's easy to
	understand how it could define the security: the more uncertain an adversary
	is about the information, the more security it has.
	
	Entropic security is introduced by Russel and Wang\cite{Russel02howto} to define
	whether the cipher text leak any predicate of the plain text. However,
	it has to require the distribution on messages has high entropy from
	the adversary's point of view. Similar entropic condition had been
	achieved in hash functions by Canetti et al\cite{Canetti97towardsrealizing, Canetti_perfectlyone-way}. 
	Hash functions are
	considered to be equivalent as deterministic encryption discussed in this
	paper: anyone could easily get a deterministic cipher text from a
	given plain text, but it's hard to find the corresponding plain text
	for a given cipher text. The only difference is that no key exists in
	hash functions and nobody could recover that plain text, while in our deterministic
	encryption, a very strong key exists and anybody who does not have that key
	could not recover that plain text. Since they key is considered unknown to adversaries 
	and	it's considered to be infinitely strong, deterministic encryption and hash functions become
	equivalent in the sense of security in our context.
	
	Entropic security has been further studied by \cite{entropic_wang}
	and its result applies to both encryption and hash functions.
	However, all their work only apply to high entropy messages.
	While for low entropy message, their results seems not work.
	One simple contradiction for hash functions has already been
	shown: enumerate all possible plain text and see which causes a collision
	will recover the original plain text easily.
	
	The key to this failure is the conditional entropy. Mutual information
	$I(X, Y)$ is widely used in those previous researches. By definition,
	\begin{equation}
		I(X, Y) = H(X) - H(X|Y)
	\end{equation}
	where $H(X)$ is the entropy of $X$ and $H(X|Y)$ is the conditional entropy
	of $X$ given $Y$\footnote{See definition \ref{def_entropy}, \ref{def_con_entropy}}.
	In their researches, $X$ is the plain text and $Y$ is the cipher text.
	Therefore, whether $I(X, Y)$ is large is the key to the security they defined.
	In traditional work, $I(X, Y)$ is required to be very small, for example $0$,
	so $Y$ does not leak much information. And $I(X, Y)$ is small
	is equivalent to that $H(X|Y)$ is large. So $I(X, Y)$ itself does not have any problem.
	The problem is what $Y$ is.
	If $Y$ is only the mere cipher text, it's meaningless when the $H(X)$ is small.
	So even in the work of \cite{entropic_wang} where $I(X, Y)$ is allowed
	to be large, the same problem exists because $Y$ is still not changed.
	In the low entropy cases, the adversary could launch simple brute force attacks,
	the information from these attacks is critical to the security. Therefore, $Y$
	should contain the information from those attacks for the security analysis.
	Thus conditional entropy $H(X|Y)$ for such $Y$ could better describe security during
	the attacks. One simple conclusion is that when $H(X|Y)$ drops to $0$, the adversary
	has compromised the security successfully because no uncertainty exists considering 
	all the information $Y$ after his or her attacks.
	
	In sum, conditional entropy $H(X|Y)$ or similar mutual information $I(X, Y)$
	has already been utilized in previous work. But in this paper, $Y$ is defined to contain the information
	gained by adversary during the brute force attacks so a better analysis
	for low entropy encryption is achieved.
	
	\subsection{Privacy Problems in Online Social Network}		
	Though defender system is currently used for only one specific LiveS Cube System,
	it is believed to be useful for many other social network
	systems for the following reasons. 
	
	Firstly, in recent years, OSNs like Facebook is becoming more and more popular, 
	so that users put a lot of their private information on the Internet, which leads 
	to serious security problems \cite{lzf1, lzf2}. Meanwhile, more and more social network systems 
	begin to notice that security based on well performed administrators and unhackable 
	servers is not reliable since human mistakes, behavior of operators and server 
	vulnerabilities are unpredictable. So hardly can anyone still totally trust servers 
	and administrators. Distributed social networks have been proposed by Buchegger 
	et al.\cite{lzf3, lzf4} to ensure distributed access control. In \cite{lzf5} a new architecture is 
	proposed to remove dependence on both the SNO(Social Network Operators) and other 
	users, while preserving the simplicity and performance of traditional centralized 
	server/client model. In this paper, a novel system based on centralized 
	server/clients is proposed to make a social network with low entropy index 
	(e.g. Phone numbers) secure and trusted in terms of both SNO and other users.
	
	Secondly, not only password is worth being protected, but identity is also worth 
	being protected as so many new social networks emerge every day. 
	[Guide to Protecting...] explains the importance of protecting the confidentiality 
	of PII (Personally Identifiable Information, e.g., user ID) and impacts of PII 
	leakage in the context of information security. It also includes a list of 
	confidentiality safeguards ranging from operational activities to technical 
	methods. Among these safeguards, some researches focus on how to minimize the 
	use, collection and retention of PII. For example, [characterizing privacy] 
	points out two defects in privacy policies of popular OSNs and provides an approach 
	to evaluating the bare minimum of private information needed for a particular set 
	of interactions. In addition, [On the leakage] carries out a detailed analysis on 
	possible ways of PII leakage via OSNs. Our work, in contrast, is based mainly on 
	two of the methods listed in [Guide to Protecting], i.e. de-identifying information 
	and anonymizing information. In this way, prevention of leakage is no longer necessary
	since neither third-party services nor the first-party server is able to retrieve 
	plain or recoverable PII data, even in ideally unbounded-computational brute force 
	attack, while the basic function of PII, i.e. identification, is remained.
	
\section{Defender Model and System}
	\subsection{Defender Model}
		Defender model is a very simple model that
		is not based on formal information theory.
		The adversary is called attacker in this model.
		The attacker can launch some attacks and after
		each attack, the attacker gains some useful information.
		Once the attacker gains enough information, the security
		is compromised.
		
		Initially, the attacker knows nothing. After
		each attack, the information attacker gains
		is described as a function $f_A$, so we define:
		\begin{align}
			I_0 &= 0\\
			I_n &= f_A(I_{n-1})\label{AONLY}
		\end{align}
		Here $I_i \in [0, 1]$ describes the amount of information
		to compromise the security after $i$
		rounds of attack: $0$ for nothing, $1$ for enough
		information to compromise the security.
		
		For a simple attacker who enumerates all possibilities, the
		function $f_A$ is quite simple:
		\begin{align}
			I_n = f_A(I_{n-1}) = I_{n-1}+c\label{AONLYE}
		\end{align}
		Here $c$ is a constant depend on how many possibilities the
		attacker has to enumerate. For example, if there are
		$m$ possibilities, $c = 1/m$. In normal situations, $m$ is more
		than $2^{128}$, so such a simple attacker just needs too many rounds
		of attack to compromise the security. Therefore, the system with
		a large $m$ is safe if the attacker is computationally-bounded.
		
		However, in some situations, the $m$ is very small. In such cases,
		we must introduce a defender against that attacker to ensure the
		security. The defender's action is also described as a function $f_D$
		so the equation(\ref{AONLY}) above becomes:
		\begin{align}
			I_n = f_A(f_D(I_{n-1}))
		\end{align}
		
		For simple attacker who enumerate all possibilities,
		there is a simple but effective defender 
		who periodically reduces the information 
		attacker has in a constant rate, so
		the equation(\ref{AONLYE}) becomes
		\begin{align}
			I_n = f_D(I_{n-1})+c = I_{n-1}/d+c
		\end{align}
		Here $d > 1$ is the rate to reduce the information.
		It can be easily conducted that:
		\begin{align*}
			\lim_{n \rightarrow \infty} I_n &= \lim_{n \rightarrow \infty} \sum_{0 \leq i < n} \frac{c}{d^i}\\
				&= \frac{c}{d-1}
		\end{align*}
		
		This means that for a small $d$ such as $2$, even $c$ is as large as
		$0.1$ and the attacker is computationally-unbounded, the attacker
		could never compromise the security.
		
	\subsection{Defender System}\label{sec_ds}
		Inspired by the simple defender model, the defender system is implemented
		in LiveS Cube system which has to generate an index
		from a given cellphone number. The defender system is to prevent attackers
		from knowing the corresponding cellphone number from its index.
		
		Define the set of cellphone number as $\mathcal X = \{x | \text{$x$ is a cellphone number}\}$.
		There's a function $f: \mathcal X \rightarrow F$ to generate index $h = f(x) \in F$ for
		a given $x$. As described before, the cellphone number set $\mathcal X$ has a very small
		size about $2^{32} \approx 10^{11}$. For a given index $h^*$, a simple attacker
		can enumerate all possible $x$ to see whether $f(x) = h^*$. Therefore, in defender
		model:
		\begin{align*}
			f_A(I_{n-1}) = I_{n-1}+c = I_{n-1}+2^{-32}
		\end{align*}
		
		So the security will be compromised after $2^{32}$ rounds of attack if there's
		no defender. The defender system is going to fullfil the defender
		function $f_D(I_{n-1}) = I_{n-1}/2$ by generating new indexes.
		In LiveS Cube system, the indexes and corresponding data entries are stored
		in database which we think attacker may have an access to. To generate
		new indexes, the system has to send indexes and data entries to a 
		secured module
		and get new indexes and data entries from that module. If attacker
		could track each new index and its old index, there's no loss of information 
		for attacker. Therefore, we have to make sure that the attacker couldn't track
		the procedure to update the indexes.
		To do that, the module is implemented in a special hardware that nobody
		could see what's going on inside the hardware without damaging it in real world.
		The best strategy againt the attacker 
		is to send all indexes and data entries to that hardware and then
		retrieve all new indexes and data entries together. By doing that, the attacker
		loses all information, which means $f_D(I_{n-1}) = 0$. However, the entries
		in database may be too many for that hardware to store. Therefore, the system
		sends two indexes and data entries from the database to hardware in one time and
		then retrieve their new indexes and data entries. After that, the attacker can
		only guess which new index is from which old index and there are $2$ possibilites.
		Thus, the defender system fullfils the equation $f_D(I_{n-1}) = I_{n-1}/2$.
		
		In short, in defender system,
		there's a function $g: F \rightarrow F$ regenerating 
		new indexes from old indexes. The defender system
		will randomly choose $h_1, h_2 \in F$ that have
		not been regenerated yet in each time and generate
		$h_1', h_2' \in F$ in a way that attacker can't tell whether
		$h_1' = g(h_1), h_2' = g(h_2)$ or $h_2' = g(h_1), h_1' = g(h_2)$.
		By doing that, the information like $f(x) = h$ becomes
		information that there's $1/2$ chance $f'(x) = h_1'$ and $1/2$ chance $f'(x) = h_2'$.
		Thus $f_D(I_{n-1}) = I_{n-1}/2$ is achieved.
		
		In real system, doing such a defend operation to update whole
		database after each possible attack costs too much.
		Therefore, the defend operation is required after $m$
		possible attack operations rather than one. Under this
		new condition, $f_D$ is unchanged, while $f_A(I_{n-1}) = I_{n-1}+c$
		becomes $f_A(I_{n-1}) = I_{n-1}+c' = I_{n-1}+m \cdot c$.
		The $m$ can be tuned in balance of security and the
		efficiency of system.
		
		The conclusions about the defender model
		and system above are not strictly
		proved because defender model itself
		is not well defined in theoretical aspect. 
		However this is a comprehensive explanation to show how and why
		defender system works. In the following section, a mathematical proof
		will be given based on information theory to demonstrate that
		the defender system can truly ensure the security even for
		a computationally-unbounded attacker, consistent with what
		is claimed here.
		
\section{Analysis of Conditional Entropy}
	\subsection{Definition and Examples}
		In this subsection, a brief definition for entropy and conditional
		entropy is given. Besides, the formal definition of defender system
		and its behaviour is given.
		Some additional examples are taken to further
		demonstrate the relation between conditional entropy and
		the security. Feel free to skip the content about
		the definition of entropy and conditional entropy if you are familiar
		with them.		
		
		\begin{mydef}[Entropy]\label{def_entropy}
			The entropy of a discrete random variable $X$ with
			possible values $\{x_1, x_2, \ldots, x_n\}$ is
			\begin{align}
				H(X) = -\sum_{i=1}^n p(x_i)\log p(x_i)
			\end{align}
			where $\log$ refers to $\log_2$ in our context.
		\end{mydef}
		
		Correspondingly, in defender system, define
		\begin{mydef}\label{def2}
			$\mathcal{X} = \{x_1, x_2, \ldots, x_n\}$ is the set of all possible 
			primary images\footnote{the primary images are cellphone numbers
			in LiveS Cube system} that index $h_i = f(x_i)$ can be calculated.
			Suppose $h^*$ is the index that attacker wants to
			get its primary image $x^* \in \mathcal{X}$ satisfying $f(x^*) = h^*$.
			The discrete random variable $X$ is the
			primary image guessed by the attacker. For convenience,
			suppose $n = 2^D$.
		\end{mydef}
		
		In ideal situation, the attacker has no related information, so $X$ should
		be uniformly distributed. In such case, the entropy is simply:
		\begin{align*}
			H(X) &= -\sum_{i=1}^{2^D} 2^{-D} \log 2^{-D}\\
				&= D
		\end{align*}
		
		\begin{mydef}[Conditional Entropy]\label{def_con_entropy}
			For a discrete random variable $X$ with
			possible values set $\mathcal X$,
			suppose that there is another random
			variable $Y$ with possible values
			set $\mathcal{Y}$, the conditional entropy
			of $X$ given $Y$ is
			\begin{align}
				H(X|Y) &= \sum_{y \in \mathcal Y} p(y) H(X | Y = y)\\
					&= -\sum_{y \in \mathcal Y} p(y) \sum_{x \in \mathcal X} p(x|y) \log p(x|y)\\
					&= -\sum_{y \in \mathcal Y} \sum_{x \in \mathcal X} p(x, y) \log p(x|y)
			\end{align}
		\end{mydef}
		
		In our context, random variable $Y$ represents the related information
		that attacker has. For example, when attacker has enumerated only one
		$x$ to calculate $f(x)$, $Y$ can be defined as $Y^{(1)}$:
		\begin{align*}
			&\mathcal Y^{(1)} = \{y \: | \: \exists x \in \mathcal X, f(x) = y\}\\
			&\forall y \in \mathcal Y^{(1)}, \; p(Y^{(1)} = y) = \frac{1}{n} = \frac{1}{2^D}\\
			&p(x|y) = \begin{cases}
				\frac{1}{n-1}, &y \neq h^*\\
				0, &y = h^* \text{ and } f(x) \neq y\\
				1, &y = h^* \text{ and } f(x) = y
			\end{cases}
		\end{align*}
		
		Similarly, when attacker has enumerated $m$ different primary images, $Y$ can be defined
		as:
		\begin{equation*}
			\mathcal Y^{(m)} = \{ y = \{y_1, y_2, \ldots, y_m\} \: | \: \exists x_i \in \mathcal X, f(x_i) = y_i\}
		\end{equation*}
		\begin{equation*}
			\forall y \in \mathcal Y^{(m)}, \; p(Y^{(m)} = y) = \frac{1}{\binom{n}{m}}
		\end{equation*}
		\begin{equation*}
			p(x|y) = \begin{cases}
				\frac{1}{n-m}, &h^* \notin y\\
				0, &h^* \in y \text{ and } f(x) \neq h^*\\
				1, &h^* \in y \text{ and } f(x) = h^*
			\end{cases}
		\end{equation*}
		
		Therefore, $H(X | Y^{(m)})$ can be calculated as:
		\begin{align*}
			H(X | Y^{(m)}) &= \sum_{y \in \mathcal Y^{(m)}} p(y) H(x | Y^{(m)} = y)\\
				&= \sum_{h^* \in y} p(y) H(x | Y^{(m)} = y) + \\
					& \;\;\;\; \sum_{h^* \notin y} p(y) H(x | Y^{(m)} = y)\\
				&= 0+\frac{\binom{n-1}{m}}{\binom{n}{m}} \log(n-m)\\
				&= \frac{n-m}{n} \log(n-m)
		\end{align*}
		
		It's clear that as $m$ increases, 
		the conditional entropy decreases and drops to $0$ when $m = n-1$. 
		Consistent with the intuition, the conditional
		entropy which notifies the security decreases about linearly when $m$ is small 
		compared with $n$.
		
	\subsection{Proof of a Simple Lower Bound}
		As the example above demonstrates, the key to the calculation
		of conditional entropy $H(X|Y)$ is the definition of the condition $Y$.
		To make a simple proof for the lower bound, we can simplify the
		condition to achieve that. Before defining $Y$, let's
		more clearly clarify how defender system behaviours first. Clear
		definition of $X$ can be found in definition \ref{def2}
		if that is unclear.
		
		The defender system will allow attacker to do at most $m$ possible
		attack operations before one defend operation. More specifically, between
		two operations of updating the whole database about the indexes and data entries,
		at most $m$ indexes are calculated from primary indexes. It's formally defined
		as:
		\begin{mydef}[Defender System]
			There are functions $f_0, f_1, f_2, \ldots$ where
			$f_0$ denotes the most recent function $f: \mathcal{X} \rightarrow F$
			to generate an index $f(x) = h \in F$ from primary image $x$. 
			Besides, $f_1$ denotes the last one used before update, $f_2$ for the last but one and so on.
			There are also functions $g_0, g_1, g_2, \ldots$ where
			$g_i$ is an update function $g_i: F \rightarrow F$ such that
			$f_i(x) = g_i(f_{i+1}(x))$. Considering the capability of hardware and security,
			$g_i$ is designed in a way that:
			\begin{align*}
				\{g_i(f_{i+1}(x_1)), g_i(f_{i+1}(x_2))\} &= \{ f_i(x_1), f_i(x_2)\}\\
					 &= G_i(x_1, x_2)
			\end{align*}
			But attacker don't know whether $g_i(f_{i+1}(x_1)) = f_i(x_1)$ or
			$g_i(f_{i+1}(x_1)) = x_2$. 
			Here, set $G_i$ is defined for convenience in later proof and
			it's also totally random
			to the attacker. \footnote{See section \ref{sec_ds} for the purpose
			of $g$}
		\end{mydef}
		
		To better describe the interaction between attacker and defender
		system, candidate sets and collision sets is defined as following
		\begin{mydef}[Candidate and Collision Set]
			Candidate sets are $C_0, C_1, C_2, \ldots$ recursively defined as
			\begin{align*}
				C_0 &= \{h^*\}\\
				C_i &= \{h | \exists G_{i-1}(x_1, x_2),
					g_{i-1}(h) \in G_{i-1}(x_1, x_2) \text{ and } \\
					& \;\;\;\;\;\;\; G_{i-1}(x_1, x_2) \cap C_{i-1} \neq \emptyset \} \;\;(i \geq 1)
			\end{align*}
			Here $h^*$ is the index that attacker wants to know its primary image
			$x$ such that $f_0(x) = h^*$. And collision sets are $K_0, K_1, K_2, \ldots$ where
			\begin{align*}
				K_i = \{h | f_i(x) = h \text{ is enumerated by attacker and } h \in C_i \}
			\end{align*}
		\end{mydef}
		
		The candidate set $C_i$ can be described as the set of indexes of $f_i$ that could be
		updated to $h^*$ through $g_0, g_1, \ldots, g_{i-1}$. The collision set $K_i$ is the
		subset of $C_i$ that are enumerated by the attacker. Since $g_i$ and $f_i$ is random
		to attacker and a maximum of $m$ indexes are allowed to be calculated using $f_i$, 
		the random distribution of $|K_i|$ is only related to $|C_i|$ and has a maximum
		of $m$. 
		
		Now condition $Y$ will be simply defined as following:
		\begin{mydef}[Simple Condition $Y_d$]
			$Y_d$ is a random variable with values set
			$\mathcal Y = \{ \alpha, \beta \}$ where
			$Y_d = \alpha$ means that $|C_d| = 2^d$
			and $|K_0| = |K_1| = \ldots = |K_{d-1}| = 0$.
			Otherwise $Y_d = \beta$.
		\end{mydef}
		
		By the definition of conditional entropy,
		\begin{align*}
			H(X|Y) &= p(Y = \alpha) H(X | Y = \alpha) + p(Y = \beta) H(X | Y = \beta)\\
				&\geq p(Y = \alpha) H(X | Y = \alpha) + 0
		\end{align*}
		
		To prove a simple lower bound, three lemmas are proposed.
		The first one shows a lower bound for $H(X | Y = \alpha)$
		and the other two prove a lower bound for $p(Y = \alpha)$.
		The final lower bound of $H(X | Y)$ will be achieved by putting
		them together.
		
		\begin{mylemma}\label{lem1}\footnote{See definition \ref{def2} for $D$}
			$H(X|Y_d = \alpha) \geq d \cdot (1-\frac{dm^2}{2^D-m+1})$
		\end{mylemma}
		
		\begin{proof}
			When $Y_d = \alpha$, the attacker
			is just unlucky in last $d$ updates
			and our defender system is lucky
			to expand $C_d$ quickly.
			In this case, the best that attacker
			may have is to know all relations
			like $f_d(x) = h$ for $x \in \mathcal X$.
			
			In addition, $H(A) \geq H(A|B)$ for
			any $A, B$, which simply means that knowing something
			more can never be a bad thing. Let $A = X | Y_d = \alpha$
			and $B$ be whether there is any $x \in C_d$ that
			has been enumerated using $f_0, f_1, \ldots, f_{d-1}$ 
			by the attacker or not.
			Then
			\begin{align*}
				H(X | Y_d = \alpha) &= H(A)\\
					&\geq H(A | B)\\
					&\geq p(B = false) \cdot H(A | B = false)
			\end{align*}
			
			When $B = false$, each $f_d(x_i) = h_i \in C_d$
			has an equal chance of $f_0(x_i) = h^*$. Therefore
			we have:
			\begin{align*}
				H(A | B = false) &\geq -\sum_{i = 1}^{2^d} \frac{1}{2^d} \log(\frac{1}{2^d})\\
					&= d
			\end{align*}
			
			For $p(B = false)$, use simple counting method:
			\begin{align*}
				p(B = false) &= \frac{\binom{n-dm}{m}}{\binom{n}{m}}\\
					&= \frac{(n-dm)\ldots(n-dm-m+1)}{n(n-1)\ldots(n-m+1)}\\
					&\geq (\frac{n-dm-m+1}{n-m+1})^m\\
					&= (1-\frac{dm}{n-m+1})^m\\
					&\geq 1-\frac{dm^2}{n-m+1}
			\end{align*}
			
			So finally:
			\begin{align*}
				H(X | Y_d = \alpha) &\geq p(B = false) \cdot H(A | B = false)\\
					&\geq d \cdot (1-\frac{dm^2}{n-m+1})\\
					&= d \cdot (1-\frac{dm^2}{2^D-m+1})
			\end{align*}
		\end{proof}
		
		To prove a lower bound of $p(Y = \alpha)$, the following fact is used.
		$(Y = \alpha)$ is equivalent to $\left(|C_d| = 2^d \text{ and } |K_i| = 0	\; (0 \leq i < d)\right)$.
		Therefore 
		\begin{align*}
			p(Y = \alpha) &= p(|C_d| = 2^d)\\
				& \;\;\;\;\; \cdot p(|K_i| = 0	\; (0 \leq i < d) \; \backslash \; |C_d| = 2^d)
		\end{align*}
		The following two lemmas are for $p(|C_d| = 2^d)$ and $p(|K_i| = 0	\; (0 \leq i < d) \; \backslash \; |C_d| = 2^d)$ 
		respectively.
		
		\begin{mylemma}
			\begin{align*}
				p(|C_d| = 2^d) \geq 1-\frac{d \cdot 2^{2d-2}+d \cdot 2^{d-1}}{2^D-1}
			\end{align*}
		\end{mylemma}
		
		\begin{proof}
			$|C_d| = 2^d$ means that $G_i(x_1, x_2) \cap C_i \leq 1$
			for all $G_i(i \leq d-1)$. Define
			\begin{align*}
				p(A_i) = p\left((\forall G_i(x_1, x_2), G_i(x_1, x_2) \cap C_i \leq 1)
					 \; \backslash \; |C_i| = 2^i\right)
			\end{align*}
			So
			\begin{align*}
				p(|C_d| = 2^d) &= \prod_{i=0}^{d-1} p(A_i)
			\end{align*}
			
			It's obvious that $\forall i < d, p(A_i) \geq p(A_{d-1})$, therefore
			\begin{align*}
				&p(|C_d| = 2^d) \\
				&\geq p(A_{d-1})^d\\
				&= P^d
			\end{align*}
			
			$P$ here can be easily estimated by counting method as
			\begin{align*}
				P &= \frac{(n-2^{d-1})\ldots(n-2^d+1)\cdot (n-2^d-1)!!}{(n-1)!!}\\
					&= \frac{(n-2^{d-1})(n-2^{d-1}-1)\ldots (n-2^d+1)}{(n-1)(n-3)\ldots(n-2^d+1)}
			\end{align*}
			
			Since
			\begin{align*}
				\frac{n-2^{d-1}-i}{n-1-2i} \geq \frac{n-2^{d-1}-j}{n-1-2j} & \text{ when } i \geq j
			\end{align*}
			
			It can be conducted that
			\begin{align*}
				P &= \frac{(n-2^{d-1})(n-2^{d-1}-1)\ldots (n-2^d+1)}{(n-1)(n-3)\ldots(n-2^d+1)}\\
					&\geq (\frac{n-2^{d-1}}{n-1})^{2^{d-1}}
			\end{align*}
			
			Thus
			\begin{align*}
			p(|C_d| = 2^d) &\geq P^d\\
				&\geq (\frac{n-2^{d-1}}{n-1})^{d \cdot 2^{d-1}}\\
				&= (1-\frac{2^{d-1}+1}{n-1})^{d \cdot 2^{d-1}}\\
				&\geq 1-\frac{d \cdot 2^{2d-2}+d \cdot 2^{d-1}}{n-1}\\
				&= 1-\frac{d \cdot 2^{2d-2}+d \cdot 2^{d-1}}{2^D-1}
			\end{align*}
		\end{proof}
		
		\begin{mylemma}
			\begin{align*}
			&p(|K_i| = 0	\; (0 \leq i < d) \; \backslash \; |C_d| = 2^d) \\
				&\geq 1-\frac{m^2}{2^D-2^{d-1}+1}
			\end{align*}
		\end{mylemma}
		
		\begin{proof}
			\begin{align*}
				&p(|K_i| = 0	\; (0 \leq i < d) \; \backslash \; |C_d| = 2^d) \\\
					&\geq p(|K_{d-1}| = 0 \; \backslash \; |C_{d-1}| = 2^{d-1})^d\\
					&= \left(\frac{\binom{n-2^{d-1}}{m}}{\binom{n}{m}} \right)^d\\
					&\geq (1-\frac{2^{d-1}m}{n-m+1})^d	\; \\
					& \;\;\;\;\;\; \text{ (see proof of lemma\ref{lem1} for similar conclusion})\\
					&= 1-\frac{2^{d-1}m d}{n-m+1}
			\end{align*}
		\end{proof}
		
		By putting them together, here comes the lower bound
		\begin{align*}
			H(X | Y_d) &\geq p(Y_d = \alpha) \cdot H(X | Y_d = \alpha)\\
				&= p(|C_d| = 2^d) \\
					&\;\;\;\;\;\; \cdot p(|K_i| = 0	\; (0 \leq i < d) \; \backslash \; |C_d| = 2^d) \\
					&\;\;\;\;\;\; \cdot H(X | Y_d = \alpha)\\
				&\geq (1-\frac{d \cdot 2^{2d-2}+d \cdot 2^{d-1}}{2^D-1})\\
					&\;\;\;\;\;\; \cdot (1-\frac{2^{d-1}m d}{2^D-m+1}) 
					\cdot (1-\frac{dm^2}{2^D-m+1}) \cdot d \\
				&= B(D, m, d)
		\end{align*}
		
		Note that the condition $Y_d$ here contains all the
		information that attacker can have. It assumes that
		the attacker is computationally-unbounded and he has
		been using the system to enumerate (primary image, index) pairs
		for an infinite long time. Also note that the formula
		satisfies arbitrary number $d$. Thus, the lower bound
		of $H(X | Y)$ is the maximum value of that formula
		over all possible $d$.
		As a result, this is our final theorem:
		\begin{mytheorem}\label{thm1}
			In defender system, one index's corresponding
			primary image's conditional entropy has a lower bound of
			\begin{align*}
				\max_{0 \leq d \leq D} \left\{ B(D, m, d) \right\}
			\end{align*}
			considering all the information
			that a computationally-unbounded attacker can
			have in an infinite long time. Here $m$ is
			the maximum number of indexes that are allowed to be calculated
			between defend operations and $D = \log(n)$ denotes the
			logarithm of the size of primary image set.
		\end{mytheorem}
		
		The formula above is a little complex. A much easier asymptotic result
		could be derived from that complex formula. Suppose that
		$d = c_1 D, m = 2^{c_2 D} \; (c_1, c_2 < 1)$ and $D$ is large enough:
		\begin{align*}
			H(X | Y_d) &= B(D, m, d)\\
						&= \left(1-\frac{c_1 \cdot D}{ 2^{D-2 c_1 D+2} } + o(1) \right)\\
							&\;\;\;\;\; \cdot \left(1-\frac{c_1 D}{2^{D-c_1 D+1 - c_2 D}} + o(1) \right)\\
							&\;\;\;\;\; \cdot \left(1-\frac{c_1 D}{2^{D-2 c_2 D}} + o(1) \right) \cdot c_1 D\\
		\end{align*}
		Therefore, when $2c_1, c_1+c_2, 2c_2 < 1$, for example $c_1 = c_2 = 1/3$,
		and $D$ is large enough, there exists:
		\begin{align*}
			m &= 2^{c_2 D} = 2^{\Omega(D)}\\
			H(X | Y_d) &= c_1D+o(D) = \Omega(D)
		\end{align*}		
		So following theorem is derived:
		\begin{mytheorem}
			In defender system, one index's corresponding
			primary image's conditional entropy has a lower bound of $\Omega(D)$
			considering all the information
			that a computationally-unbounded attacker can
			have in an infinite long time and one defend operation
			is enforced after $2^{\Omega(D)}$ calculations of indexes.
			Here $D = \log(n)$ denotes the
			logarithm of the size of primary image set.
		\end{mytheorem}
		
	\subsection{Concrete Lower Bound and Approximate Estimation}
		In LiveS Cube system, $D = 32$ and $m$ should be
		choosed in balance of security and efficiency.
		
		In the following graph, the simple lower
		bound we proved when $m = 2^{11}, 2^{12}, 2^{13}, 2^{14}$ is given
		in figure \ref{lb_m}
		
		\begin{figure}[!t]
		\centering
		\includegraphics[width=3in]{lb_m.eps}
		\caption{Lower Bound over d}\label{lb_m}
		\end{figure}		

		Since our lower bound in theorem \ref{thm1} is a maximum value
		over $d$, the $x$-axis is $d$ and the peak of each line
		is the lower bound for each $m$. As it shows, when $m = 2^{12} = 4096$, the lower
		bound is about $11.2$. This means that the system can achieve
		a relative high lower bound and keep its efficiency at the same time:
		there is only one update operation after thousands of index calculations.
		
		In fact, the proved lower bound in theorem \ref{thm1} is so
		simple and the tight lower bound is expected to be much higher.
		Observing the proof of theorem \ref{thm1}, only the
		entropy in the situation $Y = \alpha$ is count and
		all other entropy is considered to be $0$. However, in
		many situations that $Y = \beta$, there is still a high entropy.
		What's more, $B = false$ is also assumed and the attacker is
		given an extra information about whether all his enumerated $x$
		in recent $d$ updates are in candidate set $C_d$ or not, though
		in real situation this is unknown to the attacker.
		
		To have a strictly proved and very tight lower bound
		is a little hard.
		So there's an approximate lower bound which is not
		strictly proved, but should be more tight.
		In this approching,
		the size of candidate set is
		considered to be growing in an equivalent
		constant rate $r \in (1, 2)$ which
		should be very close to $2$.
		And in collision set $K_i$, each
		element has an equal chance of
		$r^{-i}$ to become $h^*$.
		Suppose that the attacker
		has enumerated $f_i(x) = h$
		for $k$ rounds, i.e. $0 \leq i < k \leq \log_r(n)$. Here
		$i < \log_r(n)$ because when
		$|C_i| = n$, the information that
		attacker can still acquire through
		enumeration is considered to be $0$.
		Under these unproved assumptions,
		a formal proof can be given to show that the lower bound
		$H(X | Y) \geq 18$ holds when $m = 2^{20}$. 
		The detailed derivation is however too complex
		to write here.
		
	\subsection{Experimental Evaluation}
		For convenience, define
		\begin{align*}
		 p_1 &= p(B = false)
		 p_2 &= p(|C_d| = 2^d)\\
		 p_3 &= p(|K_i| = 0 \; (i \leq 0 < d) \; \backslash |C_d| = 2^d)\\
		\end{align*}
		In our simple proof of the lower bound, $p_1$,
		$p_2$ and $p_3$ are 
		three key points to the final result.
		They represent that candidate sets are maximized in
		last $d$ updates, collision sets are minimized in
		last $d$ updates and candidate set $C_d$ is totally unknown
		to the attacker respectively.
		Lower bound for each of them has been proved:
		\begin{align*}
			p_1 &\geq 1-\frac{d \cdot 2^{2d-2}+d \cdot 2^{d-1}}{2^D-1}\\
			p_2 &\geq 1-\frac{m^2}{2^D-dm+1}\\
			p_3 &\geq 1-\frac{m^2}{2^D-2^{d-1}+1}
		\end{align*}
		
		By putting them together, lower bound $H(X | Y_d)$ is achieved:
		\begin{align*}
			H(X | Y_d) &\geq p_1 \cdot p_2 \cdot p_3 \cdot d\\
				&\geq B(D, m, d)
		\end{align*}
		
		$p_1 \cdot p_2 \cdot p_3$ can be measured in a real program which 
		simulates the same behaviour as we defined in defender system.
		So the proof above can be checked by this experimental measurement.
		Moreover, this experiment will show how tight our lower bound is
		when $H(X | Y_d = \beta)$ and $H(A | B = true)$ are ignored.
		Our experiment program simply simulates the whole process of $d$ updates
		for $10000$ times and records the number of successful events
		to estimate the real possibility $p_1 \cdot p_2 \cdot p_3$.
		
		Figure \ref{p13} shows the result when $m = 2^{13}$
		
		\begin{figure}[!t]
		\centering
		\includegraphics[width=3in]{p13.eps}
		\caption{$p_1 \cdot p_2 \cdot p_3$ when $m = 2^{13}$}\label{p13}
		\end{figure}

		It can be seen that the simple lower bound is not too
		far away from the experimental result when $m = 2^{13}$.
		
		Figure \ref{p14} shows the result when $m = 2^{14}$.
		\begin{figure}[!t]
		\centering
		\includegraphics[width=3in]{p14.eps}
		\caption{$p_1 \cdot p_2 \cdot p_3$ when $m = 2^{13}$}\label{p14}
		\end{figure}
		
		It seems that when $m$ is large, the simple lower bound
		estimated is much smaller than experimental result. Therefore,
		there is still plenty of room to improve the lower bound
		to make it tight, even if $H(X | Y_d = \beta)$ and $H(A | B = true)$ 
		are ignored. Meanwhile, the lower bound that can be proved should
		be higher than we simply get from theorem \ref{thm1}.
		For example, when $m = 14$, the experimental result
		of $p_1 \cdot p_2 \cdot p_3$ shows a lower bound of $10$
		when $d = 11$, while our simple lower bound only shows $4$
		when $d = 8$.
		
		To check that the simple lower bound is far from the experimental
		result only when $m$ is large, one more experiment is conducted
		when $m = 2^{11}$ and the result is shown in figure \ref{p11}.
		\begin{figure}[!t]
		\centering
		\includegraphics[width=3in]{p11.eps}
		\caption{$p_1 \cdot p_2 \cdot p_3$ when $m = 2^{13}$}\label{p11}
		\end{figure}
		
		They are very close so now it's confirmed that our estimation
		of $p_1, p_2, p_3$ is correct and accurate when $m$ is small.
		
		In sum, it has been checked that our simple lower bound
		is valid and it is indeed not so tight even if we ignore
		$H(X | Y_d = \beta)$ and $H(A | B = true)$, especially
		when $m$ is large. In the experiment,
		it shows that when $D = 32$ and $m = 2^{14} = 16384$, the lower bound
		is still at least $10$.

\subsection{Min-Entropy and More Meaningful Security}
	All the analysis above is based on Shannon entropy defined in definition \ref{def_entropy}.
	Min-entropy $H_\infty(X)$ define the entropy in a new way that
	\begin{align*}
		H_\infty(X) = \min_{x \in \mathcal X} \left(-\log p\left(X = x\right) \right)
	\end{align*}
	The conditional entropy could be similarly defined using min-entropy.
	
	The simple proof above also applies to this min-entropy
	because $p(x | Y = y)$ is either $0$ or $2^{-d}$ which means:
	\begin{align*}
		-log(0) = \infty > -log(2^{-d}) = d
	\end{align*}
	More specifically,
	$p_1 \cdot p_2 \cdot p_3$ denotes the probability that $p(x | Y = y) = 2^{-d}$.
	And the proof shows a lower bound of $p_1 \cdot p_2 \cdot p_3$
	leading to the final lower bound of conditional Shannon entropy $p_1 \cdot p_2 \cdot p_3 \cdot d$
	which is identical to conditional min-entropy.
	As it can be seen that min-entropy's definition is easier than
	Shannon entropy, it's easier to find out the practical meaning of the lower
	bound for conditional min-entropy. For min-entropy with a determinant condition,
	$H_\infty(X | Y = y) = h$
	denotes the highest probability $2^{-h}$ that adversary can achieve to guess
	the right answer when $Y = y$ is known.
	Since $H_\infty(X | Y) = E\left(H_\infty(X | Y = y)\right)$,
	conditional min-entropy just means the expected highest
	possibility that one adversary can guess the right answer.
	Therefore, the proof of our conditional entropy shows that
	the expected highest possibility that a computationally-unbounded
	adversary can compromise the security is very small: $2^{-\Omega(D)}$.
	
	Since $h$ is either $d$ or $0$ as in our proof,
	the conditional min-entropy $H_\infty(X | Y)$
	is
	\begin{align*}
		&E\left(H_\infty(X | Y = y)\right)\\
		&=p\left(H_\infty(X | Y = y) = d\right) \cdot d = p_1 \cdot p_2 \cdot p_3 \cdot d
	\end{align*}
	whose key is the chance to still confuse the adversary with 
	$2^d$ equally possible uncertainties.
	
	So as in the graph of $p_1 \cdot p_2 \cdot p_3$ when 
	$m = 2^{11}$ displayed above, both simple lower
	bound and experimental result show that
	there is a chance greater than $95\%$ percent that the adversary
	will be confused with $2^{12}$ equally possible uncertainties
	even if he or she is computationally-unbounded and has been attacking
	for an infinite long time, as long as one defend operation is enforced
	after $2^{11}$ index calculations.

	[TODO floating graph]

% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation Results}
%\label{fig_sim}
%\end{figure}

% Note that IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command, the
% \label for the overall figure must come after \caption.
% \hfil must be used as a separator to get equal spacing.
% The subfigure.sty package works much the same way, except \subfigure is
% used instead of \subfloat.
%
%\begin{figure*}[!t]
%\centerline{\subfloat[Case I]\includegraphics[width=2.5in]{subfigcase1}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{subfigcase2}%
%\label{fig_second_case}}}
%\caption{Simulation results}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.


% An example of a floating table. Note that, for IEEE style tables, the 
% \caption command should come BEFORE the table. Table text will default to
% \footnotesize as IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that IEEE does not put floats in the very first column - or typically
% anywhere on the first page for that matter. Also, in-text middle ("here")
% positioning is not used. Most IEEE journals/conferences use top floats
% exclusively. Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the \fnbelowfloat
% command of the stfloats package.



\section{Conclusion}
	To ensure the security of deterministic encryption
	for low entropy information such as cellphone numbers,
	a simple defender model is proposed. Though the result
	of this model is not strictly proved, it gives a comprehensive
	explanation how the security is ensured.
	Based on defender model, defender system is implemented in LiveS Cube
	system. To strictly prove its security in information theory,
	a simple lower bound of conditional entropy is given.
	Conditional entropy measures the difficulty for an adversary
	to get the plain information from all the related information
	he or she already has.
	The proof shows that a relative high lower bound
	under computationally-unbounded adversaries can be guaranteed
	when the efficiency is also kept.
	Asymptotically, suppose that the original entropy is $D$,
	a lower bound for conditional entropy of $\Omega(D)$ can be
	achieved when only one defend operation is required after
	$2^{\Omega(D)}$ attacks.
	And from the aspect of min-entropy, our proof shows that
	such an adversary is expected to compromise our security
	in a chance less than $2^{-\Omega(D)}$.
	However, the simple lower bound derived
	is believed to be not so tight according to an approximate lower bound 
	and an experiment. The experiment shows that the lower bound
	should be much higher even if a lot of things are ignored as
	in the proof especially when attackers are allowed to do many
	attacks before one defend operation. 
	
	In sum, a strictly proved lower bound of conditional entropy
	in defender system is given
	and the tight lower bound should be still much higher than that.
	So it's theoretically secured and should be more secured in practical.	
	
	Though defender system is now only used in specific LiveS Cube system,
	it is believed that it will have a contribution to many other social
	network systems because deterministic encryption for low entropy
	information is undeniable when encrypted index or identity has to be made
	from information that can be easily memorized by human. This system will
	make it easy to eliminate security dependency of social network operators
	or servers
	and meanwhile still keep the simplicity and easy accessibility of
	client/server architecture than distributed architecture.
	
	In the future work, what conditional entropy really means to
	real situation and what important and practical
	result can we derive from the lower bound of
	conditional entropy is worth researching.
	It's also worthy to establish a tighter lower bound
	for the system in the future, although this is
	a little hard.

% conference papers do not normally have an appendix


% use section* for acknowledgement
\section*{Acknowledgment}


The authors would like to thank...
more thanks here


% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,paper}

\begin{thebibliography}{1}

\bibitem{cond_entropy:1}
Theresa M. Korn; Korn, Granino Arthur. \emph{Mathematical Handbook for Scientists and Engineers: 
	Definitions, Theorems, and Formulas for Reference and Review}. \hskip 1em plus
  0.5em minus 0.4em\relax New York: Dover Publications. pp. 613C614. ISBN 0-486-41147-8.
  
\bibitem{cond_entropy:2}
C. Arndt (2001). \emph{Information Measures: Information and its description in Science and Engineering)}. 
\hskip 1em plus 0.5em minus 0.4em\relax Berlin: Springer. pp. 370C373. ISBN 3-540-41633-1.

\end{thebibliography}

% that's all folks
\end{document}


