
%% bare_conf.tex
%% V1.3
%% 2007/01/11
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.7 or later) with an IEEE conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE!
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_jrnl_compsoc.tex
%%*************************************************************************

% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. IEEE's font choices can trigger bugs that do  ***
% *** not appear when using other class files.                            ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



% Note that the a4paper option is mainly intended so that authors in
% countries using A4 can easily print to A4 and see how their papers will
% look in print - the typesetting of the document will not typically be
% affected with changes in paper size (but the bottom and side margins will).
% Use the testflow package mentioned above to verify correct handling of
% both paper sizes by the user's LaTeX system.
%
% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
\documentclass[10pt, conference, compsocconf]{IEEEtran}
% Add the compsocconf option for Computer Society conferences.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 4.0 (2003-05-27) and later if using hyperref.sty. cite.sty does
% not currently provide for hyperlinked citations.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found as epslatex.ps or
% epslatex.pdf at: http://www.ctan.org/tex-archive/info/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


%\usepackage{mdwmath}
%\usepackage{mdwtab}
% Also highly recommended is Mark Wooding's extremely powerful MDW tools,
% especially mdwmath.sty and mdwtab.sty which are used to format equations
% and tables, respectively. The MDWtools set is already installed on most
% LaTeX systems. The lastest version and documentation is available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/mdwtools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.


%\usepackage{eqparbox}
% Also of notable interest is Scott Pakin's eqparbox package for creating
% (automatically sized) equal width boxes - aka "natural width parboxes".
% Available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/eqparbox/





% *** SUBFIGURE PACKAGES ***
%\usepackage[tight,footnotesize]{subfigure}
% subfigure.sty was written by Steven Douglas Cochran. This package makes it
% easy to put subfigures in your figures. e.g., "Figure 1a and 1b". For IEEE
% work, it is a good idea to load it with the tight package option to reduce
% the amount of white space around the subfigures. subfigure.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at:
% http://www.ctan.org/tex-archive/obsolete/macros/latex/contrib/subfigure/
% subfigure.sty has been superceeded by subfig.sty.



%\usepackage[caption=false]{caption}
%\usepackage[font=footnotesize]{subfig}
% subfig.sty, also written by Steven Douglas Cochran, is the modern
% replacement for subfigure.sty. However, subfig.sty requires and
% automatically loads Axel Sommerfeldt's caption.sty which will override
% IEEEtran.cls handling of captions and this will result in nonIEEE style
% figure/table captions. To prevent this problem, be sure and preload
% caption.sty with its "caption=false" package option. This is will preserve
% IEEEtran.cls handing of captions. Version 1.3 (2005/06/28) and later
% (recommended due to many improvements over 1.2) of subfig.sty supports
% the caption=false option directly:
%\usepackage[caption=false,font=footnotesize]{subfig}
%
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/
% The latest version and documentation of caption.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/caption/




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/



%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Documentation is contained in the stfloats.sty comments as well as in the
% presfull.pdf file. Do not use the stfloats baselinefloat ability as IEEE
% does not allow \baselineskip to stretch. Authors submitting work to the
% IEEE should note that IEEE rarely uses double column equations and
% that authors should try to avoid such use. Do not be tempted to use the
% cuted.sty or midfloat.sty packages (also by Sigitas Tolusis) as IEEE does
% not format its papers in such ways.





% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/misc/
% Read the url.sty source comments for usage information. Basically,
% \url{my_url_here}.





% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}
\usepackage{hyperref}
\usepackage{graphicx}
\newtheorem{mydef}{Definition}
\newtheorem{mylemma}{Lemma}
\newtheorem{mytheorem}{Theorem}
\newtheorem{mycor}{Corollary}

\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{The Power of Refresh: a Novel Mechanism for Securing Low Entropy PII}
%\title{Analysis of a Novel Mechanism for Securing Low Entropy PII}
%\title{Dictionary Attack Resistant System for Low Entropy PII}


% author names and affiliations
% use a multiple column layout for up to two different
% affiliations

\author{\IEEEauthorblockN{Yuqian Li, Yang Liu, Zhifang Liu, Zhen Chen}
\IEEEauthorblockA{Department of Computer Science and Technology\\
Tsinghua University\\
Beijing 10084, China\\
\{liyuqian79, lywander, chimneyliu\}@gmail.com, zhenchen@tsinghua.edu.cn}
%\and
%\IEEEauthorblockN{Authors Name/s per 2nd Affiliation (Author)}
%\IEEEauthorblockA{line 1 (of Affiliation): dept. name of organization\\
%line 2: name of organization, acronyms acceptable\\
%line 3: City, Country\\
%line 4: Email: name@xyz.com}
}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
%
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3},
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle


\begin{abstract}
    Deterministic encryption for low entropy personally identifiable information
    (PII) is vulnerable
    to dictionary attack. It is particularly so because
    of an expedient method to enumerate possible PII's
    plain text instead of all possible keys.
    Deterministic encryption, however,
    is indispensable in the generation of hash or index of PII.

    This paper briefly presents a novel mechanism
    to frustrate dictionary attacks
    by refreshing the encryption in an external blackbox.
    The major part of this paper is about the analysis
    of this novel mechanism.
    The use of conditional entropy in this paper both measures the increased
    difficulty for attack and proves the value and feasibility
    of this novel mechanism.
    A lower bound for conditional entropy
    against a computationally-unbounded adversary is guaranteed.
    The essential meaning of the lower bound is also
    given based on min-entropy.

\end{abstract}

\begin{IEEEkeywords}
personally identifiable information; online social network; conditional entropy; deterministic encryption;
security;

\end{IEEEkeywords}


% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
% no \IEEEPARstart
    Personally identifiable information (PII) often has
    a very low entropy (e.g. cellphone numbers) for human memorization.
    In online social network (OSN), PII(e.g. cellphone numbers,
    email addresses) is often used as the information
    to identify a particular user as the usernames.
    As OSN become more and more popular,
    protecting PII leakage from both social network operators (SNO)
    and other users is more important than ever.

%   Deterministic encryption for an information from
%   a very small domain set is important for some social
%   network systems such as LiveS Cube. LiveS Cube\footnote{this is a system still
%   under developing} is a system to
%   build a social network based on the address books in cellphones.
%   In that social network, each node is indexed by a cipher text generated
%   from the cellphone number
%   of its user. Therefore, a huge network could be easily established
%   using existing address books in numerous of cellphones without
%   any additional effort of the users. However, cellphone numbers are
%   one of the most important privacy[ref] so the security of preventing
%   someone getting the corresponding cellphone number from its index
%   is the base of the system.

    OSN could use deterministic encryption of PII,
    because it both protects the plain text and provides quick identification
    and indexing.
    Although seems to be safe, deterministic encryption is
    vulnerable to dictionary attacks, especially
    on a level that is independent on SNO.
    To put it simple, the online identification system explicitly
    allows for dictionary attack, because the system can hardly tell
    the difference between a normal human behaviour and a carefully
    designed automatic brute force dictionary attack. A dictionary
    attack that simulates normal human behaviour and enumerates all
    possible values of PII's plain text is feasible unless the encryption
    schema changes. But a change of encryption schema is impossible
    for both cost and user-convenience considerations.

    Once the dictionary attack has enumerated all possible values
    of PII's plain text and established a table which maps all cipher texts
    to corresponding plain texts, the conditional entropy \cite{math_book, info_measure}
    which measures the uncertainty of the plain text given
    its corresponding cipher text and that table, is $0$.
    Even for high entropy PII, a
    computationally-unbounded adversary could establish that table
    and the conditional entropy drops to $0$ again.
    So conditional entropy given
    all information achieved by adversary during attacks
    could be a better measurement of the security.

	Therefore, to ensure the security,
	this paper proposes a novel mechanism to guarantee the
	lower bound of conditional entropy for even computationally-unbounded
	adversaries. This mechanism is called defender mechanism
	since it's based on a defender model which introduces
	a defender to balance the attacker(adversary). 
	A defender mechanism has already been implemented
    in an OSN system which uses cellphone numbers
    to identify users and establish social networks.
	In that mechanism, the defender simply refreshes
	the encryption in an external blackbox periodically.
    The analysis of the mechanism shows that a lower bound
    of conditional entropy can be guaranteed efficiently: suppose that the original entropy
    is $E$, a lower bound of conditional entropy $\Omega(E)$ can be guaranteed
    by performing one defend operation after $2^{\Omega(E)}$
    possible attacks.
    Experiments confirm that
    our lower bound is valid. Based on min-entropy, a corollary shows that
    the expected chance to guess the right plain text is only $2^{-\Omega(E)}$ for
    a computationally-unbounded adversary.

%   In conclusion, the major contributions are as follows:
%   \begin{enumerate}
%       \item To secure low entropy PII's deterministic encryption,
%       defender model and mechanism are proposed.
%       \item To analysis defender mechanism's security,
%       a proof of conditional entropy's lower bound
%       is given.
%       \item Experiments
%       are conducted to evaluate our analysis.
%   \end{enumerate}

    The rest of this paper is organized as follows.
    Section \ref{sec_rw} provides a brief literature review on privacy problems in OSN and
    entropic security. Section \ref{sec_def} introduces the defender model and mechanism.
    Section \ref{sec_proof} provides a proof as well as experiments and its essential meaning.

%   Related work about entropic security
%   and privacy problems in OSN are reviewed in section 2. In
%   section 3, defender model and mechanism are introduced.
%   A proof and some experiments for the
%   lower bound of conditional entropy are given in section 4,
%   along with the essential
%   meaning of our result based on min-entropy.
%   At last, we conclude the paper in section 5.

%   In the first section, related work about entropic security
%   and privacy problems in OSN are reviewed.
%   In the second section, defender model and system will be
%   introduced. In the third section, a proof and some experiments
%   for the lower bound of conditional entropy
%   are given. The essential meaning of our result is also given based on min-entropy
%   in the third section.

% You must have at least 2 lines in the paragraph with the drop letter
% (should never be an issue)

\section{Related Work}  \label{sec_rw}
    \subsection{Privacy Problems in Online Social Network}
    Security of online PII becomes an important concern \cite{lzf1, lzf2} because
    of the growing popularity of OSNs, such as Facebook and
    the growing tendency for users to share their information
    on OSNs.
    Meanwhile, more and more users
    become aware of that security based on well performed
    management and shielded
    servers is not reliable since human mistakes, behavior of operators and server
    vulnerabilities are unpredictable.

    Buchegger et al.\cite{lzf3, lzf4} proposes the use of distributed social networks
    to control access and
    remove security dependence on the SNO(Social Network Operators) and other users.
    The same could be achieved by traditional centralized server/client model
    to preserve the simplicity and performance, such as the one proposed in \cite{lzf5}.
    This kind of security which is independent on SNO is also the one 
    this paper wants to achieve.
%   In \cite{lzf5} a new architecture is proposed for the same purpose,
%   while preserving the simplicity and performance of traditional centralized server/client model.
    The difference is that, this paper focuses on making a social network using low entropy PII
    (e.g. cellphone numbers) for identifying and indexing secure and trusted. 
    Meanwhile, the rich functionality and efficiency of identifying and indexing 
    should also be kept as well as security.

	It's necessary to ensure the security of low entropy PII. However,
    traditional websites tend to encrypt only password of users in the whole server side,
    but store recoverable plain text of PII, especially usernames. 
    As more and more new OSNs emerge every day,
    if the security of PII could not be guaranteed,
    one OSN could be easily threatened by another OSN's PII and password leakage. \cite{guide}
    explains the importance of protecting the confidentiality of PII
    and impacts of PII leakage in the
    context of information security. It also includes a list of confidentiality
    safeguards ranging from operational activities to technical methods. Among
    these safeguards, some researches focus on how to minimize the use and
    collection of PII. For example, \cite{charact} points out two defects
    in privacy policies of popular OSNs and provides a method to find the minimum
    of private information needed for a particular set of interactions. In addition,
    \cite{leakage} carries out a detailed analysis on possible ways of PII
    leakage via OSNs. Our work, which is a different approach, is based mainly
    on another two of the methods listed in \cite{guide}, i.e. de-identifying
    information and anonymizing information. With the combination of these two ways,
    prevention of leakage is no longer necessary, since neither third-party services
    nor the first-party (the party that directly serves the user) server is able to
    retrieve plain or recoverable PII data.

    \subsection{Entropy and Entropic Security}
    Entropy\cite{entropy} measures the uncertainty of an information. Intuitively, it's easy to
    understand: the cipher text is regarded as secure
    if the adversary is uncertain about the plain text.

    Entropic security is introduced by Russel and Wang\cite{Russel02howto} to define
    whether the cipher text leak any predicate of the plain text. However,
    it requires messages to have high entropy from
    the adversary's point of view. Similar entropic condition had been
    achieved in hash functions by Canetti et al\cite{Canetti97towardsrealizing, Canetti_perfectlyone-way}.
    Hash functions are
    considered to be equivalent to deterministic encryption discussed in this
    paper: anyone could get a deterministic cipher text from a
    given plain text, but it's hard to find the corresponding plain text
    for a given cipher text. Entropic security has been further
    studied by \cite{entropic_wang}
    and its result applies to both encryption and hash functions.

    However, all of their work only apply to high entropy messages.
    While for low entropy message,
    one simple contradiction has already been
    shown: enumerate all possible plain texts and a successful collision
    will recover the original plain text easily.

    The key to this failure is the conditional entropy. Mutual information
    $I(X, Y)$ is widely used in the researches mentioned above. By definition,
    \begin{equation}
        I(X, Y) = H(X) - H(X|Y)
    \end{equation}
    where $H(X)$ is the entropy of $X$ and $H(X|Y)$ is the conditional entropy
    of $X$ given $Y$ (See definition \ref{def_entropy}, \ref{def_con_entropy}).
    In their work, $X$ is the plain text and $Y$ is the cipher text.
    Whether $I(X, Y)$ is small is key to the security they defined.
    Note that $I(X, Y)$ is small
    is equivalent to that $H(X|Y)$ is large so $I(X, Y)$ itself does not have any problem.
    The problem is what $Y$ is.
    If $Y$ is only the cipher text, it's not suitable for the case that $H(X)$ is small.
    In the low entropy cases where the adversary could easily launch dictionary attacks,
    the information from these attacks is critical to the security. Therefore, $Y$
    should contain the information from those attacks for a better security analysis.

    In summary, conditional entropy $H(X|Y)$ or equivalent mutual information $I(X, Y)$
    has already been utilized in previous work. In their work, $Y$ only
    contains the information of cipher text, while in this paper, $Y$ is defined to contain the information
    gained by adversary during the dictionary attacks so a better analysis
    for low entropy encryption is achieved.

\section{Defender Model and Mechanism}\label{sec_def}
    \subsection{Defender Model}
        The defender model is a simple model
        to intuitively describe the process about how the adversary
        (called attacker in this model) attacks step by step
        and how the defender is against the attacker correspondingly.
		
		If only attacker exists,
		after each attack, some useful information is gained by the attacker.
        Once enough information is achieved by attacker,
        the security is compromised.

        Initially, the attacker knows nothing. After
        each attack, the information gained
        is described as a function $f_A$, so define:
        \begin{align}
            I_0 &= 0\\
            I_r &= f_A(I_{r-1})\label{AONLY}
        \end{align}
        Here $I_r \in [0, 1]$ describes the amount of information
        gained after $r$ attacks: $0$ for nothing, $1$ for enough
        information to compromise the security.

        For attacker who enumerates all possibilities such
        as dictionary attacker, the
        function $f_A$ is:
        \begin{align}
            I_r = f_A(I_{r-1}) = I_{r-1}+c\label{AONLYE}
        \end{align}
        where $c = 1/n$ is a constant depend on $n$,
        the number of possible instances to be enumerated.
        In high entropy situations, $n$ is very large (e.g. greater than $2^{128}$)
         so such an attacker needs too many
        attacks to compromise the security. Therefore, the system with
        a large $n$ is secured if the attacker is computationally-bounded.

        However, for low entropy PII, $n$ is very small so
        a defender is introduced against that attacker.
        The defender's action is described as a function $f_D$
        so the equation(\ref{AONLY}) becomes:
        \begin{align}
            I_r = f_A(f_D(I_{r-1}))
        \end{align}
        which means that defender will reduce the information
        gained by attacker before a new attack can be made.

        For attackers who enumerate all possibilities,
        a defender
        who periodically reduces the information gained by
        attacker in a constant rate will be effective. With
        that defender,
        the equation becomes
        \begin{equation}
            I_r = f_A(f_D(I_{r-1})) = f_D(I_{r-1})+c = I_{r-1}/d+c
        \end{equation}
        Here $d > 1$ is the rate to reduce the information.
        It can be easily conducted that:
        \begin{equation*}
            \lim_{r \rightarrow \infty} I_r = \lim_{r \rightarrow \infty} \sum_{0 \leq i < r} \frac{c}{d^i}
                = \frac{d \cdot c}{d-1}~, ~(d > 1)
        \end{equation*}

        This means that for a $d$ such as $2$, even $c$ is as large as
        $0.1$ (so without defender only $10$ attacks will compromise
        the security) and the attacker is computationally-unbounded
        (as the $r \rightarrow \infty$ says), security will
        never be compromised.
        
        This model gives an abstract illustration about how to frustrate
        dictionary attacks for low entry PII.
        In the following sections, $f_A$ will be replaced by a formal definition
       	about dictionary attacks in a special system.
        In that system, a special designed hardware (i.e. a blackbox) 
        will be used to achieve $f_D$.
        And the information $I$ will be formally
        measured by conditional entropy $H(X|Y)$: the greater $H(X|Y)$
        is, the smaller $I$ is.

    \subsection{Defender Mechanism}\label{sec_ds}
        Based on defender model, a defender mechanism is implemented
        in a specific OSN
        which generates encrypted indexes
        from given PII. That PII are cellphone numbers
        in that specific OSN and the defender mechanism is to prevent attackers
        from knowing the corresponding cellphone number from its index.
        The defender mechanism also applies to other PII and cellphone numbers are introduced
        in this paper only for a concrete analysis and better understanding.
        In the specific OSN, indexes and corresponding encrypted user data entries are stored
        in server's database.

        The defender mechanism is going to fulfil the defender
        function $f_D(I_{r-1}) = I_{r-1}/2$ by updating indexes.
        But If the attacker
        could track each new index from its old index, there's no loss of information
        for attacker so it has to make sure that the procedure to update the indexes
        is untrackable.
        This paper suggests a scenario that attackers(e.g. SNO) already
        escalated their privilege to root access for
        both server and database. Therefore, the system has to send
        indexes and data entries to another
        secured module and get new indexes and encrypted data
        entries from that module.
        The module is implemented in a special hardware (something
        like TPM, i.e. Thusted Platform Module) that nobody
        could see what's going on inside the hardware without damaging it in real world.

        The best update strategy
        is to send all indexes and data entries to that hardware and then
        retrieve all new indexes and data entries together. By doing that, the attacker
        loses all information, which means $f_D(I_{r-1}) = 0$. However, the entries
        in database may be too many for that hardware to store. Therefore, in defender mechanism,
        all the $n$ indexes and data entries are randomly partitioned into
        $n/2$ pairs by server or SNO.
        After the partition,
        two indexes and data entries in each pair are sent and retrieved
        between the database and hardware at a time. After that, the attacker can
        only guess which new index is from which old index from $2$ possibilites.
        Thus, the equation $f_D(I_{r-1}) = I_{r-1}/2$ is fulfilled, intuitively.

        The partition and update is enforced by the hardware so SNO
        and server can't bypass them. And in
        different updates, the random partitions are also different
        and independent.

%        In short, in defender mechanism,
%        there's a function $g: F \rightarrow F$ regenerating
%        new indexes from old indexes. The defender mechanism
%        will randomly choose $h_1, h_2 \in F$ that have
%        not been regenerated yet in each time and generate
%        $h_1', h_2' \in F$ in a way that attacker can't tell whether
%        $h_1' = g(h_1), h_2' = g(h_2)$ or $h_2' = g(h_1), h_1' = g(h_2)$.
%        By doing that, the information like $f(x) = h$ becomes
%        information that there's $1/2$ chance $f'(x) = h_1'$ and $1/2$ chance $f'(x) = h_2'$.
%        Thus $f_D(I_{n-1}) = I_{n-1}/2$ is achieved.

        In real system, doing such a defend operation to update whole
        database after each possible attack costs too much.
        Therefore, the defend operation is required after $m$
        possible attack operations rather than one. Under this
        new condition, $f_D$ is unchanged, while $f_A(I_{r-1}) = I_{r-1}+c$
        becomes $f_A(I_{r-1}) = I_{r-1}+c' = I_{r-1}+m \cdot c$.
        The $m$ can be tuned in balance of security and the
        efficiency. The formal mathematical definition for
        defender mechanism's behavior will be given in the
        next section.

\section{Analysis of Conditional Entropy}\label{sec_proof}
    This section gives out a proof 
    and a demonstration
    of the defender mechanism's security under a computationally-unbounded attacker
    in information theory.

    The first subsection below will demonstrate the definition
    of entropy and conditional entropy along with some
    definitions and examples in our context. The second subsection
    will give a proof to the a lower bound for conditional entropy.
    In the third subsection, experiments
    are conducted to evaluate the result and an essential meaning based on min-entropy 
    of our lower bound is given.

    \subsection{Definition and Example}
        In this subsection, a brief definition for entropy and conditional
        entropy is given along with the formal definition of defender mechanism
        and its behaviour.
        Some additional examples are taken to further
        demonstrate the relation between conditional entropy and
        the security.

        \begin{mydef}[Entropy\cite{entropy}]\label{def_entropy}
            The entropy of a discrete random variable $X$ with
            possible values $\{x_1, x_2, \ldots, x_n\}$, denoted as  $H(X)$, is
            \begin{equation}
                H(X) = -\sum_{i=1}^n p(x_i)\log p(x_i)
            \end{equation}
            where $\log$ refers to $\log_2$ in our context.
        \end{mydef}

        Correspondingly, in defender mechanism, define
        \begin{mydef}[Attacker's Guess $X$]\label{def2}
            $\mathcal{X} = \{x_1, \ldots, x_n\}$ is the set of all possible
            primary images.
            For convenience, define $n = 2^E$.
            The function $\varepsilon: \mathcal X \rightarrow Z$ is to generate index $z = \varepsilon(x)$
            in a very large index space $Z$. For example, padding many deterministic bits to $x$ and use
            a very long key to deterministic encrypt it. Considering all possible paddings
            and keys, $Z$ is a very large space to adversaries.
            Suppose $z^*$ is the index that attacker wants to
            get its primary image $x^* \in \mathcal{X}$ satisfying $\varepsilon(x^*) = z^*$.
            The discrete random variable $X$ is the
            primary image guessed by the attacker against $x^*$.
        \end{mydef}
 
 		In our context, primary images refer to PII.
 		In our specific OSN, PII are cellphone numbers
		whose set $\mathcal X$ has a very small
        size about $10^{10} \approx 2^{32}$.

        In ideal situation, the attacker has no related information, so $X$ should
        be uniformly distributed:
        \begin{align*}
            H(X) &= -\sum_{i=1}^{n} \frac{1}{n} \log \frac{1}{n}
            	= -\sum_{i=1}^{2^E} 2^{-E} \log 2^{-E}
                = E
        \end{align*}

        \begin{mydef}[Conditional Entropy\cite{math_book, info_measure}]\label{def_con_entropy}
            For a discrete random variable $X$ with
            possible values set $\mathcal X$ and another random
            variable $Y$ with possible values
            set $\mathcal{Y}$, the conditional entropy
            of $X$ given $Y$ is
            \begin{align}
                H(X|Y) &= \sum_{y \in \mathcal Y} p(y) H(X | Y = y)\\
                    &= -\sum_{y \in \mathcal Y} p(y) \sum_{x \in \mathcal X} p(x|y) \log p(x|y)
            \end{align}
        \end{mydef}

        In our context, $Y$ represents the related information
        achieved by attacker. In the special case that attacker has enumerated only one
        $x$ to get $\varepsilon(x)$, $Y^{(1)}$ can be defined as:
        \begin{align*}
            &\mathcal Y^{(1)} = \varepsilon(\mathcal X) = \{y \: | \: \exists x \in \mathcal X, \varepsilon(x) = y\}\\
            &\forall y \in \mathcal Y^{(1)}, \; p(Y^{(1)} = y) = \frac{1}{|\mathcal Y^{(1)}|} = \frac{1}{n}\\
            &p(x|y) = \begin{cases}
                \frac{1}{n-1}, &y \neq z^*\\
                0, &y = z^* \text{ and } \varepsilon(x) \neq z^*\\
                1, &y = z^* \text{ and } \varepsilon(x) = z^*
            \end{cases}
        \end{align*}

        Similarly, when attacker has enumerated $m$ different primary images, $Y^{(m)}$ can be defined
        as:
        \begin{equation*}
            \mathcal Y^{(m)} = \{ y = \{y_1, y_2, \ldots, y_m\} \: | \: y_i \in \mathcal Y^{(1)}\}
        \end{equation*}
        \begin{equation*}
            \forall y \in \mathcal Y^{(m)}, \; p(Y^{(m)} = y) = \frac{1}{|\mathcal Y^{(m)}|} = \frac{1}{\binom{n}{m}}
        \end{equation*}
        \begin{equation*}
            p(x|y) = \begin{cases}
                \frac{1}{n-m}, &z^* \notin y\\
                0, &z^* \in y \text{ and } \varepsilon(x) \neq z^*\\
                1, &z^* \in y \text{ and } \varepsilon(x) = z^*
            \end{cases}
        \end{equation*}

        Therefore, $H(X | Y^{(m)})$ can be calculated as:
        \begin{align*}
            H(X | Y^{(m)}) %&= \sum_{y \in \mathcal Y^{(m)}} p(y) H(x | Y^{(m)} = y)\\
                &= \sum_{z^* \in y} p(y) H(x | Y^{(m)} = y) + \\
                    & \;\;\;\; \sum_{z^* \notin y} p(y) H(x | Y^{(m)} = y)\\
                &= 0+\frac{\binom{n-1}{m}}{\binom{n}{m}} \log(n-m)\\
                &= \frac{n-m}{n} \log(n-m)
        \end{align*}

        As $m$ increases,
        the conditional entropy decreases and drops to $0$ when $m = n-1$.
        Consistent with the intuition, the conditional
        entropy which notifies the security decreases about linearly when $m$ is small
        compared with $n$.

        To make a simple proof, we can simplify the
        condition $Y$ and preserve the information it contains
        at the same time. Before defining $Y$, a
        formal definition of how defender mechanism behaviours is given. Clear
        definition of $X$ can be found in definition \ref{def2} in the above.

        The defender mechanism will allow at most $m$ possible
        attacks (i.e. calculate $m$ pairs of $\left(x, z = \varepsilon(x)\right)$) 
        before carrying out one defend operation. More specifically, between
        two operations of updating the indexes,
        at most $m$ indexes are calculated from primary images(i.e. cellphone numbers).
        It's formally defined as:
        \begin{mydef}[Defender Mechanism]
            There are functions $\varepsilon_0, \varepsilon_{-1}, \varepsilon_{-2}, \ldots$ where
            $\varepsilon_0$ denotes the most recent function $\varepsilon: \mathcal{X} \rightarrow Z$
            to generate an index $\varepsilon(x) = z \in Z$ from primary image $x$.
            Besides, $\varepsilon_{-1}$ denotes the last one used before update, $\varepsilon_{-2}$ 
            for the last but one and so on.
            For each $\varepsilon_{-i}$, at most $m$ indexes $\varepsilon_{-i}(x)$ can be calculated.
            There are also functions $g_0, g_{-1}, g_{-2}, \ldots$ where
            $g_{-i}$ is an update function $g_{-i}: Z \rightarrow Z$ such that
            $\varepsilon_{-i}(x) = g_{-i}\left(\varepsilon_{-(i+1)}(x) \right)$. Considering the capability of hardware,
            in $i$th recent update,
            $n$ primary images $\mathcal X$ are partitioned into $n/2$ pairs randomly:
            \begin{align*}
            	P_{-i, j} = \{x_1, x_2\} ~, ~ (0 \leq j < n/2)
            \end{align*}
            The $g_i\left(\varepsilon_{-(i+1)}(P_{-i, j} = \{x_1, x_2\})\right)$ for one pair:
            \begin{align*}
            	g_i\left(\varepsilon_{-(i+1)}(P_{-i, j})\right) = \{ g_i\left(\varepsilon_{-(i+1)}(x_1)\right),
            		g_i\left(\varepsilon_{-(i+1)}(x_2)\right) \}
            \end{align*}
            is 
            calculated in the hardware at a time. All indexes are updated by using
            $g_i$ to all $n/2$ pairs $P_{-i, j}$.
            Since the hardware is a blackbox, the attacker can only track 
            $\varepsilon_{-(i+1)}(P_{-i, j})$ and
            \begin{align*}
            	\varepsilon_{-i}(P_{-i, j}) = g_{-i}\left( \varepsilon_{-(i+1)}(P_{-i, j}) \right)
            \end{align*}
            for each $P_{-i, j}$.
            But the attacker don't know whether $g_{-i}(\varepsilon_{-(i+1)}(x_1)) = \varepsilon_{-i}(x_1)$ or
            $g_{-i}(\varepsilon_{-(i+1)}(x_1)) = \varepsilon_{-i}(x_2)$.
            Here, $P_{-i, j}$ are totally random
            to the attacker and independent for different $i$.
        \end{mydef}

        To better describe the interaction among attacks
        and defends, candidate sets and collision sets are defined.
		The candidate set $C_{-i}$ can be described as the set of indexes
        calculated by $\varepsilon_{-i}$ that are possible to be
        updated to $z^*$ through $g_0, g_{-1}, \ldots, g_{-(i-1)}$. The collision set $K_{-i}$ is the
        subset of $C_{-i}$ that is enumerated by the attacker.
        \begin{mydef}[Candidate and Collision Set]
            Candidate sets are $C_0, C_{-1}, C_{-2}, \ldots$ recursively defined as
            \begin{align*}
                C_0 &= \{z^*\}\\
                C_{-(i+1)} &= \{z | \exists P_{-i, j},~
                    g_{-i}(z) \in \varepsilon_{-i}(P_{-i, j}) \text{ and } \\
                    & \;\;\;\;\;\;\; \varepsilon_{-i}(P_{-i, j}) \cap C_{-i} \neq \emptyset \}
            \end{align*}
            Here $z^*$ is the index that attacker wants to know its primary image
            $x^*$ such that $\varepsilon_0(x^*) = z^*$. And collision sets are $K_0, K_{-1}, K_{-2}, \ldots$ where
            \begin{equation*}
                K_{-i} = \{z | \varepsilon_{-i}(x) = z \text{ is calculated and } z \in C_{-i} \}
            \end{equation*}
        \end{mydef}
        
        Note that the greater $|C_{-i}|$ is and the smaller $|K_{-i}|$ is,
        the more uncertain $x^*$ is for attacker given this certain
        condition. In our measurement
        of conditional entropy $H(X|Y)$, $Y$ is also a random variable,
        which means the condition itself is uncertain. $H(X|Y)$ is
        an average of entropy with certain condition $H(X|Y = y)$ 
        over the distribution of $p(Y = y)$.

        Now define condition $Y_r$ that contains all information
        attacker achieved during infinite attacks. Here subscript $r$
        is a parameter to simplify condition's definition:
        \begin{mydef}[Simple Condition $Y_r$]
            $Y_r$ is a random variable with values set
            $\mathcal Y = \{ \alpha, \beta \}$ where
            $Y_r = \alpha$ means that $|C_{-r}| = 2^r$
            and $|K_{-i}| = 0~(0 \leq i < r)$.
            Otherwise $Y_r = \beta$.
            Here $r$ is a parameter to denote the number
            of updates that defender mechanism is lucky,
            i.e. the best condition for defender is gotten.
        \end{mydef}

        By the definition of conditional entropy,
        \begin{align*}
            H(X|Y_r) &= p(Y_r = \alpha) H(X | \alpha) + p(Y_r = \beta) H(X | \beta)\\
                &\geq p(Y_r = \alpha) H(X | \alpha) + 0
        \end{align*}
        
        Here, the second part is just counted as $0$ since it's non-negative.
        In other words, to get the lower bound of the conditional entropy $H(X | Y_r)$,
        an average of entropy $H(X | Y_r = y)$ over all possible conditions $y \in \mathcal Y$, 
        all $H(X | Y_r = y)$ is counted as minimum value $0$, except for the best condition
        $Y_r = \alpha$.

    \subsection{Proof of a Lower Bound}
    	Now let's prove a lower bound of $H(X | Y_r)$.
    	Note that $Y_r$ contains all information that attacker can achieve,
    	so a lower bound of $H(X | Y_r)$ should also be a lower
    	bound of any $H(X | Y)$ where $Y$ is a condition denotes any
    	information achieved by attacker under defender mechanism.
    	
        To prove the lower bound, three lemmas are proposed.
        The first one shows a lower bound of $H(X | Y_r = \alpha)$
        and the other two for a lower bound of $p(Y_r = \alpha)$.
        The lower bound of $H(X | Y_r)$ is achieved by putting
        them together.

        \begin{mylemma}\label{lem1}
        \begin{align*}
            H(X|Y_r = \alpha) \geq r \cdot (1-\frac{r m \cdot 2^r}{2^E-2^r+1}) ~,~(2^r < 2^E - r m)
        \end{align*}
        \end{mylemma}

        \begin{IEEEproof}
            When $Y_r = \alpha$, the attacker
            is unlucky in last $r$ updates
            and defender is lucky
            to expand $C_{-r}$ quickly.
            In this case, the best that attacker
            could still know are all relations
            like $\varepsilon_{-r}(x) = z$ for all $x \in \mathcal X$.

            In addition, $H(A) \geq H(A|B)$ for
            any $A, B$, which simply means that knowing something
            more can never be a bad thing. Let $A = (X | Y_r = \alpha)$
            and $B$ be whether there is any $\varepsilon_{-r}(x) \in C_{-r}$ whose $x$
            has been enumerated using $\varepsilon_0, \varepsilon_{-1}, \ldots, \varepsilon_{-(r-1)}$
            by the attacker or not.
            Then
            \begin{align*}
                H(X | Y_r = \alpha) %&= H(A)\\
                    &\geq H(A | B)\\
                    &\geq p(B = false) \cdot H(A | B = false)
            \end{align*}

            When $B = false$, each $\varepsilon_{-r}(x_i) = z_i \in C_{-r}$
            has an equal chance of $\varepsilon_0(x_i) = z^*$. Therefore:
            \begin{align*}
                H(A | B = false) &\geq -\sum_{i = 1}^{2^r} \frac{1}{2^r} \log(\frac{1}{2^r})
                    = r
            \end{align*}

            For $p(B = false)$, use simple counting method:
            \begin{align*}
                p(B = false) &= \frac{\binom{n-r m}{2^r}}{\binom{n}{2^r}}\\
                    &= \frac{(n-r m)\ldots(n-2^r-r m+1)}{n(n-1)\ldots(n-2^r+1)}\\
                    &\geq (\frac{n-2^r-r m+1}{n-2^r+1})^{2^r}\\
                    &= (1-\frac{r m}{n-2^r+1})^{2^r}\\
                    &\geq 1-\frac{r m \cdot 2^r}{2^E-2^r+1}
            \end{align*}

            So finally:
            \begin{align*}
                H(X | Y_r = \alpha) &\geq p(B = false) \cdot H(A | B = false)\\
                    &= r \cdot (1-\frac{r m \cdot 2^r}{2^E-2^r+1})
            \end{align*}
        \end{IEEEproof}

        To prove a lower bound of $p(Y_r = \alpha)$, note that
        $(Y_r = \alpha)$ is equivalent to $\left(|C_{-r}| = 2^r \text{ and } |K_{-i}| = 0   \; (0 \leq i < r)\right)$.
        Therefore
        \begin{align*}
            p(Y_r = \alpha) &= p(|C_{-r}| = 2^r)\\
                & \;\;\;\;\; \cdot p(|K_i| = 0  \; (0 \leq i < r) \; \backslash \; |C_{-r}| = 2^r)
        \end{align*}
        The following two lemmas are for $p(|C_{-r}| = 2^r)$ and $p(|K_{-i}| = 0  \; (0 \leq i < r) \; \backslash \; |C_{-r}| = 2^r)$
        respectively.

        \begin{mylemma}
            \begin{align*}
                p(|C_{-r}| = 2^r) \geq 1-\frac{r \cdot 2^{2r-2}+r \cdot 2^{r-1}}{2^E-1}
            \end{align*}
        \end{mylemma}

        \begin{IEEEproof}
            $|C_{-r}| = 2^r$ means that $\varepsilon_{-i}(P_{-i, j}) \cap C_{-i} \leq 1$
            for all $P_{-i, j}~(i \leq r-1)$. Define
            \begin{align*}
                p(D_i) = p\left((\forall P_{-i, j}, P_{-i, j} \cap C_{-i} \leq 1)
                     \; \backslash \; |C_{-i}| = 2^i\right)
            \end{align*}
            So
            \begin{align*}
                p(|C_{-r}| = 2^r) &= \prod_{i=0}^{r-1} p(D_i)
            \end{align*}

            It's obvious that $\forall i < r, p(D_i) \geq p(D_{r-1})$, therefore
            \begin{align*}
                &p(|C_{-r}| = 2^r)
                \geq p(D_{r-1})^r
                = P^r
            \end{align*}

            $P$ here can be easily estimated by counting method as
            \begin{align*}
                P &= \frac{(n-2^{r-1})\ldots(n-2^r+1)\cdot (n-2^r-1)!!}{(n-1)!!}\\
                    &= \frac{(n-2^{r-1})(n-2^{r-1}-1)\ldots (n-2^r+1)}{(n-1)(n-3)\ldots(n-2^r+1)}
            \end{align*}

            Since
            \begin{align*}
                \frac{n-2^{r-1}-i}{n-1-2i} \geq \frac{n-2^{r-1}-j}{n-1-2j} & \text{ when } i \geq j
            \end{align*}

            It can be conducted that
            \begin{align*}
                P &= \frac{(n-2^{r-1})(n-2^{r-1}-1)\ldots (n-2^r+1)}{(n-1)(n-3)\ldots(n-2^r+1)}\\
                    &\geq (\frac{n-2^{r-1}}{n-1})^{2^{r-1}}
            \end{align*}

            Thus
            \begin{align*}
            p(|C_{-r}| = 2^r) &\geq P^r\\
                &\geq (\frac{n-2^{r-1}}{n-1})^{r \cdot 2^{r-1}}\\
                &= (1-\frac{2^{r-1}+1}{n-1})^{r \cdot 2^{r-1}}\\
                &\geq 1-\frac{r \cdot 2^{2r-2}+r \cdot 2^{r-1}}{2^E-1}
            \end{align*}
        \end{IEEEproof}

        \begin{mylemma}
            \begin{align*}
            &p(|K_{-i}| = 0    \; (0 \leq i < r) \; \backslash \; |C_{-r}| = 2^{-r}) \\
                &\geq 1-\frac{2^{r-1}mr}{2^E-2^{r-1}+1}
            \end{align*}
        \end{mylemma}

        \begin{IEEEproof}
            \begin{align*}
                &p(|K_{-i}| = 0    \; (0 \leq i < r) \; \backslash \; |C_{-r}| = 2^{-r}) \\\
                    &\geq p(|K_{r-1}| = 0 \; \backslash \; |C_{r-1}| = 2^{r-1})^r\\
                    &= \left(\frac{\binom{n-2^{r-1}}{m}}{\binom{n}{m}} \right)^r\\
                    &\geq \left(1-\frac{2^{r-1}m}{n-m+1}\right)^r   \; \\
                    & \;\;\;\;\;\; \text{ (see proof of lemma\ref{lem1} for similar conclusion})\\
                    &= 1-\frac{2^{r-1}m r}{n-m+1}
            \end{align*}
        \end{IEEEproof}

        By putting them together, here comes the lower bound
        \begin{align*}
            H(X | Y_r) &\geq p(Y_r = \alpha) \cdot H(X | Y_r = \alpha)\\
                &= H(X | Y_r = \alpha) \cdot p(|C_{-r}| = 2^r) \\
                    &\;\;\;\;\;\; \cdot p(|K_{-i}| = 0 \; (0 \leq i < r) \; \backslash \; |C_{-r}| = 2^r) \\
                    %&\;\;\;\;\;\; \cdot H(X | Y_d = \alpha)\\
                &\geq (1-\frac{r \cdot 2^{2r-2}+r \cdot 2^{r-1}}{2^E-1})\\
                    &\;\;\;\;\;\; \cdot (1-\frac{2^{r-1}m r}{2^E-m+1})
                    \cdot (1-\frac{r m \cdot 2^r}{2^E-2^r+1}) \cdot r \\
                &= L(E, m, r)
        \end{align*}

        Note that $Y_r$ here contains all
        information that a computationally-unbounded
        attacker can achieve after
        using the system to enumerate (primary image, index) pairs
        for an infinite long time. Also note that the formula above
        satisfies arbitrary number $r$. Thus, the lower bound
        of $H(X | Y)$ is the maximum value of that formula
        over all possible $r$.
        As a result, this is the theorem:
        \begin{mytheorem}\label{thm1}
            Under defender mechanism,
            the primary image's conditional entropy has a lower bound of
            \begin{align*}
                \max_{0 \leq r \leq E} \left\{ L(E, m, r) \right\}
            \end{align*}
            given all the information
            that a computationally-unbounded attacker can
            have in an infinite long time. Here $m$ is
            the maximum number of indexes that are allowed to be calculated
            between defend operations and $E = \log(n)$ denotes the
            logarithm of the size of primary image set.
        \end{mytheorem}

        The formula above is a little complex. A much easier asymptotic result
        could be derived from that. Suppose that
        $r = c_1 E, m = 2^{c_2 E} \; (c_1, c_2 < 1)$ and $E$ is large enough:
        \begin{align*}
            H(X | Y_r) &= L(E, m, r)\\
                        &= \left(1-\frac{c_1 \cdot E}{ 2^{E-2 c_1 E+2} } + o(1) \right)\\
                            &\;\;\;\;\; \cdot \left(1-\frac{c_1 E}{2^{E-c_1 E+1 - c_2 E}} + o(1) \right)\\
                            &\;\;\;\;\; \cdot \left(1-\frac{c_1 E}{2^{E-2 c_2 E}} + o(1) \right) \cdot c_1 E\\
        \end{align*}
        Therefore, when $2c_1, c_1+c_2, 2c_2 < 1$, for example $c_1 = c_2 = 1/3$,
        and $E$ is large enough, there exists:
        \begin{align*}
            m &= 2^{c_2 E} = 2^{\Omega(E)}\\
            H(X | Y_r) &= c_1E+o(E) = \Omega(E)
        \end{align*}
        So the following theorem is derived:
        \begin{mytheorem}
            Under defender mechanism,
            primary image's conditional entropy has a lower bound of $\Omega(E)$
            given all the information
            that a computationally-unbounded attacker can
            have in an infinite long time when one defend operation
            is enforced after $2^{\Omega(E)}$ calculations of indexes.
            Here $E = \log(n)$ is the
            logarithm of the size of primary image set.
        \end{mytheorem}

    \subsection{Analysis of the Special Case}
        In our specific OSN dealing with cellphone numbers,
        $E = 32$.
        The simple lower
        bound proved above when $m = 2^{11}, 2^{12}, 2^{13}, 2^{14}$ is given
        in figure \ref{lb_m}.

        \begin{figure}[!t]
        \centering
        \includegraphics[width=3in, trim=0mm 0mm 0mm 20mm]{lb_m.eps}
        \caption{lower bound proved for different $m$}\label{lb_m}
        \end{figure}

        Since our lower bound in theorem \ref{thm1} is a maximum value
        over $r$, the $x$-axis is $r$ and the peak of each line
        is the lower bound for each $m$. As it shows, when $m = 2^{13} = 8192$, the lower
        bound is about $10.3$.
        Thus only one update operation after thousands of index calculations is required
        to guarantee a lower bound higher than $10$.

        In fact, the proved lower bound in theorem \ref{thm1} is so
        simple and the tight lower bound is expected to be much higher
        for the following reasons.
        Observing the proof of theorem \ref{thm1}, only the
        entropy in the situation $Y_r = \alpha$ is count. However, in
        many situations that $Y_r = \beta$, there is still a high entropy.
        What's more, $B = false$(see proof of lemma \ref{lem1}) is also assumed so the attacker is
        given an extra information about whether all his enumerated $x$
        in recent $r$ updates are in candidate set $C_{-r}$. But
        in real situation, this is unknown to the attacker.

    \subsection{Experimental Evaluation and Essential Meaning}
        For convenience, define
        \begin{align*}
         p_1 &= p(B = false)\\
         p_2 &= p(|C_{-r}| = 2^r)\\
         p_3 &= p(|K_{-i}| = 0 \; (i \leq 0 < r) \; \backslash |C_{-r}| = 2^r)
        \end{align*}
        In our proof above, $p_1$,
        $p_2$ and $p_3$ are
        three key points to the final result.
        Lower bound for each of them has been proved
        and lower bound of $H(X | Y_r)$ is achieved by:
        \begin{align*}
            H(X | Y_r) &\geq p_1 \cdot p_2 \cdot p_3 \cdot r
                \geq L(E, m, r)
        \end{align*}

        In fact, $p_1 \cdot p_2 \cdot p_3$ can be measured in a real program which
        simulates the same behaviour as defender mechanism.
        So the proof above can be evaluated by this experiment.
        Moreover, this experiment will show how tight our lower bound is
        when $H(X | Y_r = \beta)$ and $H(A | B = true)$ are ignored.

        The experiment program simply simulates the whole process of $r$ updates
        for $10000$ times and records the number of successful events
        to estimate the possibility $p_1 \cdot p_2 \cdot p_3$.

        Figure \ref{p14} show $p_1 \cdot p_2 \cdot p_3$
        when $m = 2^{14}$ and figure \ref{hp14} show the conditional entropy's
        lower bound based on $p_1 \cdot p_2 \cdot p_3$ when $m = 2^{14}$.

%        \begin{figure}[!t]
%        \centering
%        \includegraphics[width=3in, trim=0mm 0mm 0mm 20mm]{p13.eps}
%        \caption{$p_1 \cdot p_2 \cdot p_3$ when $m = 2^{13}$}\label{p13}
%        \end{figure}
%
        \begin{figure}[!t]
        \centering
        \includegraphics[width=3in, trim=0mm 0mm 0mm 20mm]{p14.eps}
        \caption{$p_1 \cdot p_2 \cdot p_3$ when $m = 2^{14}$}\label{p14}
        \end{figure}

        \begin{figure}[!t]
        \centering
        \includegraphics[width=3in, trim=0mm 0mm 0mm 20mm]{hp14.eps}
        \caption{conditional entropy's lower bound when $m = 2^{14}$}\label{hp14}
        \end{figure}

        It can be seen that the simple lower bound proved is valid and not too
        far away from the experimental result. By $p_1 \cdot p_2 \cdot p_3$
        conducted by the experiment, the lower bound of $H(X|Y)$ is greater than $10$
        when $m = 2^{14} = 16384$.

%        To check that the simple lower bound is far from the experimental
%        result only for large $m$, one more experiment is conducted
%        for $m = 2^{11}$ and shown in figure \ref{p11}
%        which confirms that our estimation
%        of $p_1, p_2, p_3$ is correct and accurate for small $m$.
%
%        \begin{figure}[!t]
%        \centering
%        \includegraphics[width=3in, trim=0mm 0mm 0mm 20mm]{p11.eps}
%        \caption{$p_1 \cdot p_2 \cdot p_3$ when $m = 2^{11}$}\label{p11}
%        \end{figure}
%
%        In sum, it has been evaluated that our simple lower bound
%        is valid while it is not so tight even if we ignore
%        $H(X | Y_d = \beta)$ and $H(A | B = true)$, especially
%        when $m$ is large. In the experiment,
%        it shows that when $D = 32$ and $m = 2^{14} = 16384$, the lower bound
%        is still at least $10$.

    All the analysis above is based on Shannon entropy.
    Min-entropy $H_\infty(X)$ define the entropy in a new way that
    \begin{align*}
        H_\infty(X) = \min_{x \in \mathcal X} \left(-\log p\left(X = x\right) \right)
    \end{align*}
    Similar conditional min-entropy could also be defined.

    The simple proof above also applies to this min-entropy
    because $p(x | Y = y)$ is either $0$ or $2^{-r}$ which implies:
    \begin{align*}
        -log(0) = \infty > -log(2^{-r}) = r
    \end{align*}
    And the lower bound for Shannon entropy and min-entropy
    in our proof is the same for the same reason.
    As it can be seen that min-entropy's definition looks simpler,
    it's easier to find out the meaning of the lower
    bound for conditional min-entropy. For min-entropy with a deterministic condition,
    $H_\infty(X | Y = y) = a$
    denotes the highest probability $2^{-a}$ that adversary can achieve to guess
    the right answer when $Y = y$ is known.
    Since $H_\infty(X | Y) = E\left(H_\infty(X | Y = y)\right)$,
    conditional min-entropy means the expected highest
    possibility that one adversary can guess the right answer.
    Therefore:
    \begin{mycor}[Essential Meaning]
    The proof of our lower bound shows that
    the expected highest possibility that a computationally-unbounded
    adversary can guess the right plain text is very small: $2^{-\Omega(E)}$.
    And it's $2^{-10}$ in the special case for $E = 32$ and $m = 2^{14}$.
    \end{mycor}
%
%    Since $a$ is either $r$ or $0$ in our proof,
%    $H_\infty(X | Y)$ is
%    \begin{align*}
%        E\left(H_\infty(X | Y = y)\right) &= p\left(H_\infty(X | Y = y) = d\right) \cdot d\\
%         &= p_1 \cdot p_2 \cdot p_3 \cdot d
%    \end{align*}
%    where $p_1 \cdot p_2 \cdot p_3$ is the chance to still confuse the adversary with
%    $2^d$ equally possible uncertainties.
%
%    So as in the graph of $p_1 \cdot p_2 \cdot p_3$ when
%    $m = 2^{11}$ displayed above, both simple lower
%    bound and experimental result show that
%    there is a chance greater than $95\%$ percent that the adversary
%    will be confused with $2^{12}$ equally possible uncertainties
%    even if he or she is computationally-unbounded and has been attacking
%    for an infinite long time, as long as one defend operation is enforced
%    after $2^{11}$ index calculations.

% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex,
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation Results}
%\label{fig_sim}
%\end{figure}

% Note that IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command, the
% \label for the overall figure must come after \caption.
% \hfil must be used as a separator to get equal spacing.
% The subfigure.sty package works much the same way, except \subfigure is
% used instead of \subfloat.
%
%\begin{figure*}[!t]
%\centerline{\subfloat[Case I]\includegraphics[width=2.5in]{subfigcase1}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{subfigcase2}%
%\label{fig_second_case}}}
%\caption{Simulation results}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table. Table text will default to
% \footnotesize as IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that IEEE does not put floats in the very first column - or typically
% anywhere on the first page for that matter. Also, in-text middle ("here")
% positioning is not used. Most IEEE journals/conferences use top floats
% exclusively. Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the \fnbelowfloat
% command of the stfloats package.



\section{Conclusion}
    To ensure the security of deterministic encryption
    for low entropy PII such as cellphone numbers,
    this paper presents a novel defender model as well
    as a defender mechanism implemented for a specific
    OSN which uses cellphone numbers to generate encrypted indexes.
    The defender mechanism also applies to PII other than
    cellphone numbers.

    This paper mainly focuses on analysis of this defender mechanism.
    A lower bound of conditional entropy is calculated to
    prove the mechanism's security for even
    computationally-unbounded adversaries while
    the system's efficiency is also kept.
    Asymptotically, suppose that the original entropy is $E$,
    a lower bound for conditional entropy of $\Omega(E)$ can be
    guaranteed when only one defend operation is required after
    $2^{\Omega(E)}$ attacks.
    Based on min-entropy, our proof shows that
    such an adversary only has an expected chance
    less than $2^{-\Omega(E)}$ to guess the right plain text.
    However, the tight lower bound 
    is believed to be much higher than we proved.

    In short, it's theoretically secured and should be more practically secured.

% conference papers do not normally have an appendix


% use section* for acknowledgement
%\section*{Acknowledgment}
%
%
%The authors would like to thank...
%more thanks here


% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,paper}

%\begin{thebibliography}{1}
%
%\bibitem{cond_entropy:2}
%C. Arndt (2001). \emph{Information Measures: Information and its description in Science and Engineering)}.
%\hskip 1em plus 0.5em minus 0.4em\relax Berlin: Springer. pp. 370C373. ISBN 3-540-41633-1.
%
%\end{thebibliography}

% that's all folks
\end{document}
